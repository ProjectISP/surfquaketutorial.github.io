{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to","text":"<p>surfQuake is a software designed to overcome the workflow process that involves the estimation of seismic source parameters. </p> <p>The complete set of toolboxes inside surfQuake allows the user the complete automation of seismic phases arrival times estimation and events association, event locations, cumputation of magnitudes and attenuation and to obtain the moment tensor inversion. The software is programmed in  Python 3  and offers the users the possibility of three programming levels. </p> <p>From the core library, which allows the user to integrate the core of surfQuake into his own scripts, to the Command Line Interface, which gives the user access to an upper layer that simplifies the use of the core. Finally, surfQuake core is wrapped by a Graphical User Interface (GUI) and connected to a SQL Lite database to store all the results. The can easily query the database tables to extract important information through the object Relational Mapper SQLAlchemy directly managed from the GUI.</p>"},{"location":"#toolboxes","title":"ToolBoxes","text":"<ul> <li>Create your Project </li> <li>Phase Picker </li> <li>Event Associator </li> <li>Event Location </li> <li>Source Parameters </li> <li>Moment Tensor Inversion </li> <li>Data Base </li> </ul>"},{"location":"#how-to-read-this-tutorial","title":"How to read this Tutorial","text":"<p>The first step is to select which programming level is the most convenient for you. We offer three levels a Graphical User Interface (user friendly), Command Line Interface (for advanced users that likes black boxes with no complications) and core library (for expert users that wants integrate surfQuake in their own scripts).</p> <p>Ok, now that you have an idea.surfQuake is divided in five parts Picking, Association, Locate, Source and MTI. For each toolbox you will find your a description of the software according to your programming level and a usage example!</p> <p>Let's start with Project  and then continue with the next toolboxes.</p> <p>GitHub Repositoris at: surfQuakeCore &amp; surfQuakeGUI</p> <p>Follow us in Twitter</p> <p>Cite us: Integrated Seismic Program (ISP) A New Python GUI\u2010Based Software for Earthquake Seismology and Seismic Signal Processing. Seismological Research Letters 2022</p>"},{"location":"associate/","title":"Arraival times Assocotiation","text":"<p>The main goal of this tool is to associate the arrival times of different P- and S-waves to the their corresponding events. The associator algorythm used in surfquake is REAL (Zhang et al., 2019). The user needs to set the input parameters and point to the folder where the picks have been storaged. In th following sections it will be describe the surfquake imprementation of REAL, for a full description of the parameters visit REAL cookbook</p>"},{"location":"associate/#events-associator-gui","title":"Events Associator GUI","text":"<p>This is a screenshot of the Associator GUI.</p> <p></p> <p>The basics settings to associate inside a medium size region (300 x 300) km are show in the upper screenshot.</p> <ul> <li>Picking Directory: Root path to the folders containing the picking files. This files are automatically generated after running the picking tool.</li> <li> <p>Output Directory: Path to the forlder where the users wants the results of the arrival times association. Picking file nll_input.txt to Event Locaion tool will be also saved in this folder.</p> </li> <li> <p>Geographic Framework: Set the coordinates of your study region and remind loading the metadata from project tool. You can plot a map to be sure tour settings are ok.</p> </li> <li>Associator Parameters: These parameters are described in this link.</li> </ul>"},{"location":"associate/#config-files","title":"Config files","text":"<p>The parametrization of the Event Assocciator tool can be storaged in a file.ini. An example of this file is as follows:</p> <pre><code>[GEOGRAPHIC_FRAME]\nLAT_REF_MAX = 43.0000\nLAT_REF_MIN = 42.0000\nLON_REF_MIN = 0.8000\nLON_REF_MAX = 2.2000\nDEPTH = 20.00\n#\n[GRID_SEARCH_PARAMETERS]\nHORIZONTAL_SEARCH_RANGE = 4.80\nDEPTH_SEARCH_RANGE = 50.00\nEVENT_TIME_WINDOW = 120.00\nHORIZONTAL_SEARCH_GRID_SIZE = 0.60\nDEPTH_SEARCH_GRID_SIZE = 10.00\n#\n[TRAVEL_TIME_GRID_SEARCH]\nHORIZONTAL_RANGE = 5.00\nDEPTH_RANGE = 50.00\nDEPTH_GRID_RESOLUTION_SIZE = 2.00\nHORIZONTAL_GRID_RESOLUTION_SIZE = 0.01\n#\n[THRESHOLD_PICKS]\nMIN_NUM_P_WAVE_PICKS = 3\nMIN_NUM_S_WAVE_PICKS = 1\nNUM_STATIONS_RECORDED = 1\n</code></pre>"},{"location":"associate/#events-associator-from-cli","title":"Events Associator from CLI","text":""},{"location":"associate/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake associator [-h] -i INVENTORY_FILE_PATH -p DATA_DIR -c CONFIG_FILE_PATH -w WORK_DIR_PATH -s SAVE_DIR [-v]\n</code></pre>"},{"location":"associate/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake associator -h\n</code></pre>"},{"location":"associate/#run-phase-picker-from-cli","title":"Run Phase Picker from CLI","text":"<pre><code>&gt;&gt; surfquake associate -i /surfquake_test/metadata/inv_all.xml -p /surfquake_test/test_picking_final -c /surfquake_test/config_files/real_config.ini\n</code></pre>"},{"location":"associate/#events-associator-from-library","title":"Events Associator from Library","text":""},{"location":"associate/#classes","title":"Classes","text":"<p><code>RealCore</code></p> <pre><code>class RealCore:\n    def __init__(self, metadata_file: str, real_config: Union[str, RealConfig], picking_directory: str, working_directory: str,\n                 output_directory: str):\n\n        \"\"\"\n        ----------\n        Parameters\n        ----------\n        metadata_file str: Path to the inventory information of stations coordinates and instrument description\n        real_config: Either the path to a real_config.ini or a RealConfig object.\n        picking_directory str: Root path to the folder wher picks P and S wave arrival time picks are storage\n        working_directory str: Root path to the folder that the associator uses to save intermediate files sucha as travel-times.\n        \"\"\"\n</code></pre>"},{"location":"associate/#methods","title":"Methods","text":"<p><code>run_real</code></p> <pre><code># instance method\ndef run_real(self):\n    # starts the events associator\n</code></pre>"},{"location":"associate/#example-using-library","title":"example using library","text":"<pre><code>from surfquakecore.real.real_core import RealCore\n\n# Inventory Information\ninventory_path = \"/meta/inv_all.xml\"\n\n# picking Output of PhaseNet\npicks_path = '/test_surfquake_core/picks'\n\n# Set working_directory and output\nworking_directory = '/test_surfquake_core/test_real/working_directory'\noutput_directory = '/test_surfquake_core/test_real/output_directory'\n\n# Set path to REAL configuration\nconfig_path = surfquake_test/config_files/real_config.ini\n# Run association\nrc = RealCore(inventory_path, config_path, picks_path, working_directory, output_directory)\nrc.run_real()\nprint(\"End of Events AssociationProcess, please see for results: \", output_directory)\n</code></pre>"},{"location":"db/","title":"DataBase","text":""},{"location":"db/#populate","title":"Populate","text":"<ul> <li>Pick in File/Read Hyp Folder to incorporate all information contained inside hyp folders. Hyp folders are the file output from location.</li> <li> <p>Pick in File/Magnitudes to populate your database with the information from the output file obtained in source toolbox.</p> </li> <li> <p>Pick in File/MTI to populate your database with the information from the output file obtained in MTI toolbox.</p> </li> </ul>"},{"location":"db/#quering","title":"Quering","text":"<p>Choose the options on the right widget to filter the hypocenter inside your DataBase. The eartquakes shown in the table can be used in the MTI GUI when runs the inversion.</p>"},{"location":"db/#phase-information","title":"Phase Information","text":"<p>Click with right button to get the phases information corresponding to the selected event</p> <p></p>"},{"location":"install/","title":"Installation","text":"<p>The user can choose either install only the core of surfQuake or install the GUI which includes also the core. In both cases, install SurfQuake from the pip repository, after create and environment (either anaconda env or pip env). </p>"},{"location":"install/#installing-the-core","title":"Installing the core","text":""},{"location":"install/#create-an-environment","title":"Create an environment","text":""},{"location":"install/#anaconda-env","title":"Anaconda env","text":"<pre><code>&gt;&gt; conda create -n myenv python=3.9 # surfQuake for 3.9 &lt;= Python &lt;= 3.11\n&gt;&gt; conda activate myenv\n</code></pre>"},{"location":"install/#pip-env","title":"pip env","text":"<p>Warning, if you are using anaconda, normally is automatically activated the base environment in your terminal. So first of all deactivate it! </p> <pre><code>&gt;&gt; (base) conda deactivate\n</code></pre> <p>To prevent dependencies from becoming incompatible, please make sure that the version of Python you have installed on your system is greater than 3.9 and less than 3.12. Simply follow these steps to view your Python version:</p> <pre><code>&gt;&gt; python\nPython 3.11.4 (main, Jul  5 2023, 09:00:44) [Clang 14.0.6 ] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information\n</code></pre> <pre><code>&gt;&gt; pip install virtualenv # install in your python the virtualenv package (just in case)\n&gt;&gt; python3 -m venv .venv # python&lt;version&gt; -m &lt;virtual-environment-name&gt; &lt;venv_location&gt; \n&gt;&gt; source venv/bin/activate #s ource &lt;venv_location&gt;\n</code></pre>"},{"location":"install/#install-the-core-package","title":"Install the core package","text":"<p>You can install surfQuake after creating your virtual environment (using either Anaconda env or Pip env).</p> <pre><code>pip install surfquake\n</code></pre>"},{"location":"install/#installing-the-gui","title":"Installing the GUI","text":"<p>Open a terminal and type:</p> <pre><code>&gt;&gt; git clone https://github.com/rcabdia/SurfQuake.git\n</code></pre>"},{"location":"install/#create-an-environment_1","title":"Create an environment","text":""},{"location":"install/#anaconda","title":"Anaconda","text":"<pre><code>&gt;&gt; conda create -n myenv python=3.9\n&gt;&gt; conda activate myenv\n</code></pre>"},{"location":"install/#pip","title":"pip","text":"<p>Warning, if you are using anaconda, normally is automatically activated the base environment in your terminal. So first of all deactivate it!</p> <pre><code>&gt;&gt; (base) conda deactivate\n</code></pre> <pre><code>&gt;&gt; pip install virtualenv\n&gt;&gt; python&lt;version&gt; -m venv &lt;virtual-environment-name&gt;\n&gt;&gt; source venv/bin/activate # activate your environment\n</code></pre>"},{"location":"install/#install-the-gui","title":"Install the GUI","text":"<p>Now, you can proceed with the installation of the full surfQuake program (core and GUI):</p> <pre><code>&gt;&gt; cd SurfQuake\n&gt;&gt; pip install -r requirements.txt\n</code></pre>"},{"location":"locate/","title":"Event Location","text":"<p>The Event Location toolbox uses Non Lin Loc, Lomax et ., 2009 to locate seismic events.</p>"},{"location":"locate/#event-location-gui","title":"Event Location GUI","text":"<p>This is a screenshot of the Event Location GUI.</p> <p></p> <ul> <li>Location Parameters: Just set the paths to the workflow.<ul> <li>Work / Ouput Directory: Set the root path where the necessary working directories structure will be created. In this structure will be build the velocity grid, travel-times tables and the location output.</li> <li>Model Folder Path: Set the path to your 1D or 3D model folder.</li> <li>Pick File: Set the path to the pick file. Picking file nll_input.txt output from associator toolbox contains all phase info o run the event locations.</li> </ul> </li> <li>Grid Configuration:<ul> <li>Grid Reference: SW corner of your geographic framework</li> <li>Grid Dimension in the x, y and z number of points and dx, dy dx the size in each dimension. For example the size in the X/East axis, X = dx*(x-1)</li> <li>Geographic Transformation: Simple or Global. Warning if Global is selected go directly to press Run Location </li> <li>Grid Type: Slowness (Default)</li> <li>Wave: P &amp; S or P. This will guide the software to know wich can of velocity grid create.</li> <li>Model: 1D or 3D</li> </ul> </li> <li>Travel Times:<ul> <li>Select type of grid GRID1D or GRID3D and the corresponding wave P &amp; S or S</li> <li>Distance Limit: The maximum distance from the center of the grid  - station,  to compute the travel-time</li> </ul> </li> <li>Location parameters:<ul> <li>search: algorythm to be used in the search of the location solution</li> <li>Method</li> </ul> </li> </ul>"},{"location":"locate/#config-file","title":"Config File","text":"<p>In the next section CLI and Library the user can configurate the event location tool from a config file type file.ini, an example is as follows:</p> <pre><code>[GRID_CONFIGURATION]\nLATITUDE = 41.0000\nLONGITUDE = 0.0000\nDEPTH_KM = -3.0\nX = 400\nY = 400\nZ = 50\nDX = 1\nDY = 1\nDZ = 1\nGEO_TRANSFORMATION = SIMPLE\nGRID_TYPE = SLOW_LEN\nPATH_TO_PICKS = /Volumes/LaCie/surfquake_test/test_real_final/nll_input.txt\nPATH_TO_1D_MODEL = /Volumes/LaCie/surfquake_test/test_nll_final/model1D\nPATH_TO_3D_MODEL = NONE\nMODEL = 1D\nP_WAVE_TYPE = TRUE\nS_WAVE_TYPE = TRUE\n#\n[TRAVEL_TIMES_CONFIGURATION]\nDISTANCE_LIMIT = 500\nGRID = 1D\n\n#\n[LOCATION_PARAMETERS]\nSEARCH = OCT-TREE\nMETHOD = GAU_ANALYTIC\n</code></pre>"},{"location":"locate/#event-location-from-cli","title":"Event Location from CLI","text":""},{"location":"locate/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake locate seismic event [-h] -i INVENTORY_FILE_PATH -c CONFIG_FILE_PATH -o OUT_DIR_PATH [-g] [-s]\n</code></pre>"},{"location":"locate/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake locate -h\n</code></pre>"},{"location":"locate/#run-event-location-from-cli","title":"Run Event Location from CLI","text":"<pre><code>&gt;&gt; surfquake locate -i /surfquake_test/metadata/inv_all.xml -c /surfquake_test/config_files/nll_config.ini -o /surfquake_test/test_nll_final -g -s\n</code></pre>"},{"location":"locate/#event-location-from-library","title":"Event Location from Library","text":""},{"location":"locate/#classes","title":"Classes","text":"<p><code>NllManager</code></p> <pre><code>class NllManager:\n\n    def __init__(self, nll_config: Union[str, NLLConfig], metadata_path, working_directory):\n        \"\"\"\n        Manage NonLinLoc program to locate seismic events.\n        :param nll_config: Path to nll_config.ini file or to NLLConfig object.\n        :param metadata_path: Path to metadata file.\n        :param working_dirctory: Root path to folder to establish the working and output structure.\n        \"\"\"\n        self.__get_nll_config(nll_config)\n        self.__location_output = working_directory\n        self.__create_dirs()\n        self.__dataless_dir = metadata_path\n        self.__metadata_manager = None\n</code></pre>"},{"location":"locate/#methods","title":"Methods","text":"<p><code>vel_to_grid</code> <pre><code># instance method\ndef vel_to_grid(self):\n    \"\"\"\n    # Method to generate the velocity grid #\n    :return: Extracts the velocity grid as layer*.buf and layer*.hdr inside working_dir/model\n    template file temp.txt in working_dir/temp.txt\n    \"\"\"\n</code></pre></p> <p><code>grid_to_time</code> <pre><code># instance method\ndef grid_to_time(self):\n    \"\"\"\n    # Method to generate the travel-time tables file #\n    :return: Extracts the travel-times per wave type as\n    [layer.P.STA.angle.buf, layer.P.STA.time.buf, layer.P.STA.time.hdr]\n    inside ./working_dir/time\n    template file at ./work_dir/temp/G2T_temp.txt\n    \"\"\"\n</code></pre></p> <p><code>run_nlloc</code> <pre><code># instance method\ndef run_nlloc(self):\n    \"\"\"\n    # Method to run the event locations from the picking file and config_file.ini #\n    :return: locations files *hyp inside ./working_dir/loc\n    template file at ./work_dir/temp/run_temp.txt\n    \"\"\"\n</code></pre></p>"},{"location":"locate/#example-using-library","title":"Example using library","text":"<pre><code>import os\nfrom surfquakecore.earthquake_location.run_nll import Nllcatalog, NllManager\n\nif __name__ == \"__main__\":\n    cwd = os.path.dirname(__file__)\n    # Basic input: working_directory, inventory file path and config_file input\n    working_directory = os.path.join(cwd, \"earthquake_locate\")\n    inventory_path = os.path.join(working_directory, \"inventories\", \"inv_surfquakecore.xml\")\n    path_to_configfiles = os.path.join(working_directory, \"config/nll_config.ini\")\n    nll_manager = NllManager(path_to_configfiles, inventory_path, working_directory)\n    nll_manager.vel_to_grid()\n    nll_manager.grid_to_time()\n    for iter in range(0, 10):\n        print('Locating ', iter)\n        nll_manager.run_nlloc()\n    nll_catalog = Nllcatalog(working_directory)\n    nll_catalog.run_catalog(working_directory)\n</code></pre>"},{"location":"mti/","title":"Autamatic Moment Tensor Inversion","text":"<p>The events foocal mechanism is estimated using a optimized version of Bayesian Isola (Vack\u00e2r et al., 2017). The MTI is run automatically over a set of events. The events can be selected quering the database through the GUI, giving a folder path with mti_config.ini files or even crating obsject for each event and the running the inversion from th cor library.</p>"},{"location":"mti/#mti-gui","title":"MTI GUI","text":"<ul> <li> <p>Working Framework:</p> <ul> <li> <p>Working Dirctory (no required): Folder where Green functions a temporal files will be saved.</p> </li> <li> <p>Output Directory: Rooth path to the folder where output from event inversions will be saved.</p> </li> <li> <p>Earth Model File: File path to he earth model. An example as follows:</p> </li> </ul> </li> </ul> <pre><code>Crustal model                  IBERIA\nnumber of layers \n   7\nParameters of the layers\ndepth of layer top(km)   Vp(km/s)    Vs(km/s)    Rho(g/cm**3)    Qp     Qs\n      0.0                 6.10       3.490        2.920         300    300\n     11.0                 6.40       3.660        2.980         300    300\n     24.0                 6.90       3.940        3.080         300    300\n     31.0                 8.00       4.570        3.300         300    300\n     45.6                 8.04       4.474        3.308         300    300\n     56.2                 8.04       4.478        3.309         300    300\n     66.9                 8.04       4.481        3.309         300    300\n*************************************************************************\n</code></pre> <ul> <li> <p>Grid search: Defines a geographic grid centered in the estimated hypocenter where surfquake will proceed with the search of the best MTI.</p> <ul> <li> <p>Horizontal Location Uncertainity: Maximum horizontal range of the search.</p> </li> <li> <p>Horizontal search step: Horizontal resolution of the grid search.</p> </li> <li> <p>Depth Uncertainty: Maximum vertical range of the search.</p> </li> <li> <p>Depth Search step: Vertical resolution of the grid search.</p> </li> <li> <p>Time Uncertainity: Time shift around the event origin time.</p> </li> </ul> </li> <li> <p>Inversion Parameters: Defines parameters realtd to the source and the inversion process.</p> </li> <li>Traces Selection Criteria: Defin the criteria to include or not seismograms to your inversion</li> </ul> <p>Now, that you have parametrized your inversion follow the steps:</p> <ol> <li>Inside Project: Load your project and load your Metadata.</li> <li>Inside The DataBase dedicated GUI.<ul> <li>Fill your DataBase loading that files from the folder where you have the location files.</li> <li>Not required but very recommended populate your DataBase with the information from the output of Source. This will give the database information about Magnitudes and will facilitate the MTI.</li> </ul> </li> <li>Make a Query to filter your Database</li> <li>Without closing DataBase GUI, press Run Inversion.</li> <li>Track the evolution of your inversions in the output dirctory, finally press print Results.</li> <li>Populate your dataBase with the information from the output of MTIs.</li> </ol>"},{"location":"mti/#mti-config-file","title":"MTI Config File","text":"<p>In the following sections CLI and Core library the user can use mti_config.ini files to define each event where surfquake will carry out the MTIs. You can storage a single event per file. So, place all files inside the same folder. Please find here an example of mti_config.ini file (the name of the .ini file doen't matter just extension .ini).</p> <pre><code>[ORIGIN]\nORIGIN_DATE = 21/08/2018 00:28:57.000\nLATITUDE = 42.7059\nLONGITUDE= -7.6974\nDEPTH_KM = 11.0\nMAGNITUDE = 3.5\n\n[STATIONS_AND_CHANNELS]\n# add the station name follow by channels split by a comma , and use .+ for all channels\nELOB = HHZ, HHN, HHE \nEPON = .+\nEMAZ = .+\n\n[MTI_PARAMETERS]\nEARTH_MODEL_FILE = /earth_models/Iberia.dat\nLOCATION_UNC = 3000\nTIME_UNC = 0.5\nDEVIATORIC = True\nDEPTH_UNC = 3000\nCOVARIANCE = True\nRUPTURE_VELOCITY = 2500\nSOURCE_TYPE = Triangle\nMIN_DIST = 50\nMAX_DIST = 500\nSOURCE_DURATION= 2\n\n[SIGNAL_PROCESSING]\nREMOVE_RESPONSE = True\nMAX_FREQ = 0.08\nMIN_FREQ = 0.04\nRMS_THRESH = 5.0\n</code></pre>"},{"location":"mti/#mti-from-cli","title":"MTI from CLI","text":""},{"location":"mti/#usage","title":"Usage","text":"<pre><code>surfquake mti -i [inventory_file_path] -p [path_to_project] -c [path to mti_config_file.ini] \n        -o [output_path]  -s [if save plots]\n</code></pre>"},{"location":"mti/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake mti -h\n</code></pre>"},{"location":"mti/#run-mti-from-cli","title":"Run MTI from CLI","text":"<pre><code>&gt;&gt; surfquake mti -i /mti_run_inversion_resources/inv_surfquakecore.xml -p /project/surfquake_project_mti.pkl -o /test_mti -c /surfquake_test/mti_configs -s\n</code></pre>"},{"location":"mti/#mti-from-library","title":"MTI from Library","text":""},{"location":"mti/#classes","title":"Classes","text":"<p><code>BayesianIsolaCore</code> <pre><code>class BayesianIsolaCore:\n    def __init__(self, project: SurfProject, inventory_file: str,\n                 output_directory: str, save_plots=False):\n        \"\"\"\n\n        :param project: SurfProject object\n        :param inventory_file: File to the metadata file\n        :param output_directory: Root path to the output directory where inversion results will be saved\n        :param save_plots: if figures summarizing the results for each inversion are desired\n        \"\"\"\n</code></pre></p>"},{"location":"mti/#methods","title":"Methods","text":"<p><code>run_inversion</code> <pre><code># instance method\ndef run_inversion(self, mti_config: Union[str, MomentTensorInversionConfig], **kwargs):\n\n    \"\"\"\n    This method should be to loop over config files and run the inversion.\n    Previously it is needed to load the project and metadata.\n\n    Args:\n        mti_config: Either a directory of .ini files, a .ini file or an instance of MomentTensorInversionConfig\n        **kwargs:\n\n    Returns:\n\n    \"\"\"\n</code></pre></p> <p><code>read_isola_result</code> <pre><code>def read_isola_result(file: str) -&gt; MomentTensorResult:\n    \"\"\"\n    Reads the ISOLA-ObsPy output inversion.json file.\n\n    :param file: The location of inversion.json from isola.\n    :return: Dict\n    \"\"\"\n</code></pre></p>"},{"location":"mti/#example-using-library","title":"Example using library","text":"<pre><code>iimport os\nfrom surfquakecore.moment_tensor.mti_parse import read_isola_log, read_isola_result\nfrom surfquakecore.moment_tensor.sq_isola_tools.sq_bayesian_isola import BayesianIsolaCore\nfrom surfquakecore.project.surf_project import SurfProject\n\ndef list_files_with_iversion_json(root_folder):\n    iversion_json_files = []\n\n    for foldername, subfolders, filenames in os.walk(root_folder):\n        for filename in filenames:\n            if filename == \"iversion.json\":\n                iversion_json_files.append(os.path.join(foldername, filename))\n\n    return iversion_json_files\n\nif __name__ == \"__main__\":\n    cwd = os.path.dirname(__file__)\n    resource_root = os.path.join(cwd, \"mti\")\n    inventory_path = os.path.join(resource_root, \"inventories\", \"inv_surfquakecore.xml\")\n    data_dir_path = os.path.join(resource_root, \"waveforms\")\n    path_to_project = os.path.join(resource_root, \"project\")\n    path_to_configfiles = os.path.join(resource_root, \"list_earthquakes\")\n    working_directory = os.path.join(resource_root, \"working_directory\")\n    output_directory = os.path.join(resource_root, \"output_directory\")\n\n    # Load the Project\n    project_name = \"mti_project.pkl\"\n    path_to_project = os.path.join(path_to_project, project_name)\n    sp = SurfProject(path_to_project)\n    sp.search_files(verbose=True)\n    print(sp)\n\n\n    # Build the class\n    bic = BayesianIsolaCore(project=sp, inventory_file=inventory_path, output_directory=output_directory,\n                            save_plots=True)\n\n    # Run Inversion\n    bic.run_inversion(mti_config=path_to_configfiles)\n    print(\"Finished Inversion\")\n    iversion_json_files = list_files_with_iversion_json(output_directory)\n\n    for result_file in iversion_json_files:\n        result = read_isola_result(result_file)\n        print(result)\n\n    # example of reading log_output file\n    #for r in bic.results:\n    #     read_isola_log(r)\n    #print(results.keys())\n</code></pre> <p>Alternatively, if you want you would prefer crat moment tensor config objects rather than point to a folder with .ini files. Then, crate objects like this:</p> <pre><code>mti_configs = [] # Create an empty list to storage mti configurations\n\ndate_str = \"28/02/2022 02:07:59.433\"\norigin_date = datetime.strptime(date_str, '%d/%m/%Y %H:%M:%S.%f')\n# still implementing test\nmti_config1 = MomentTensorInversionConfig(\n    origin_date=origin_date,\n    latitude=42.5414,\n    longitude=1.4505,\n    depth_km=5.75,\n    magnitude=3.0,\n    stations=[StationConfig(name=\"TEST1\", channels=[\"NNH\", \"NNZ\", \"NNE\"]), \n    StationConfig(name=\"TEST2\", channels=[\"NNH\", \"NNZ\", \"NNE\"])],\n    inversion_parameters=InversionParameters(\n        earth_model_file=\"earthmodel/Iberia.txt\",\n        location_unc=0.7,\n        time_unc=.2,\n        depth_unc=3.,\n        source_duration=2.0,\n        rupture_velocity=2500.,\n        min_dist=10.,\n        max_dist=300.,\n        source_type='PointSource'\n    ),\n)\n\n\nmti_cnfig2 = MomentTensorInversionConfig(....)\n........\n\nmti_configs = [mti_config1, mti_config2 .... ]\n</code></pre> <p>Then</p> <pre><code>for mti_config in list_of_mti_configs:\n    bic.run_inversion(mti_config=mti_config)\n\niversion_json_files = list_files_with_iversion_json(output_directory)\n\n    for result_file in iversion_json_files:\n        result = read_isola_result(result_file)\n        print(result)\n</code></pre>"},{"location":"picker/","title":"Phase Picker","text":"<p>The Picking algorythm of surfQuake uses the Deep Neural Network of Phasenet (Zhu and Beroza, 2019) to estimate the arrival times of P- and S-wave. The arrival times are saved as a csv file and in daily folders to be ready to be used by the associator. Example of csv header:</p> <pre><code>date,fname,year,month,day,net,station,flag,tt,date_time,weight,amplitude,phase\n20220131,CA.ARBS.P,2022,1,31,CA,ARBS,1,39383.88,2022-01-31T10:56:23.880000,0.5383206605911255,8557892.700195312,P\n20220131,CA.ARBS.S,2022,1,31,CA,ARBS,1,85480.59,2022-01-31T23:44:40.590000,0.30124416947364807,8481788.269042969,S\n</code></pre>"},{"location":"picker/#phase-picker-gui","title":"Phase Picker GUI","text":"<p>We start with the GUI. This is a screenshot of the Project GUI.</p> <p></p> <p>Be sure you have just created a Project or you have loaded one. Then click on Run Auto Pick. This action will start the phase picker and will save the output in surfquake/data/picks ready to be used in the associator toolbox and surfquake/data/original_picks as csv file for direct reading.</p>"},{"location":"picker/#phase-picker-from-cli","title":"Phase picker from CLI","text":""},{"location":"picker/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake pick -f [path to your project file] -d [path to your pick saving directory] -p [P-wave threshoold] -s [S-wave threshold] --verbose\n</code></pre>"},{"location":"picker/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake pick -h\n</code></pre>"},{"location":"picker/#run-phase-picker-from-cli","title":"Run Phase Picker from CLI","text":"<pre><code>&gt;&gt; surfquake pick -f /test_surfquake_core/testing_data/projectssurfquake_project_new.pkl -d /test_surfquake_core/testing_data/picks -p 0.3 -s 0.3 --verbose\n</code></pre>"},{"location":"picker/#phase-picker-from-library","title":"Phase Picker from Library","text":""},{"location":"picker/#classes","title":"Classes","text":"<p><code>PhasenetISP</code></p> <pre><code>class PhasenetISP:\n    def __init__(files, batch_size=3, highpass_filter=0.5, min_p_prob=0.3, min_s_prob=0.3, min_peak_distance=50, amplitude=False):\n\n    \"\"\"\n\n    Main class to initialize the picker\n\n    :param files: Dictionary with kewords addressing to seismograms file path and their corresponding metadata (i.e. sampling rate).\n    :type SurfProject: required (see Project section)\n\n    :param batch_size: Determines the number of samples in each batch (larger batch size uses more memory but can provide more accurate updates)\n    :type float:\n\n    :param highpass_filter: Lower corner frequency of highpass filter to be applied to the raw seismogram. Set to 0 to do not apply any pre-filter\n    :type float:\n\n    :param min_p_prob: Probability threshold for P pick\n    :type float:\n\n    :param min_s_prob: Probability threshold for S pick\n    :type float:\n\n    :param min_peak_distance: Minimum peak distance\n    :type float:\n\n    :param amplitude: if return amplitude value\n    :type float:\n\n    :returns:\n    :rtype: :class:`surfquakecore.phasenet.phasenet_handler.PhasenetISP`\n\n    \"\"\"\n</code></pre> <p><code>PhasenetUtils</code></p>"},{"location":"picker/#methods","title":"Methods","text":"<p><code>phasenet</code></p> <pre><code># instance method\ndef phasenet(self):\n</code></pre> <p><code>PhasenetUtils.split_picks</code></p> <pre><code>@staticmethod\ndef split_picks(picks):\n    \"\"\"\n    :param picks: A DataFrame with all pick information\n    :type picks: Pandas DataFrame\n    \"\"\"\n</code></pre> <p><code>PhasenetUtils.convert2real</code></p> <pre><code>@staticmethod\ndef convert2real(picks, pick_dir: str):\n\"\"\"\n:param picks: picks is output from method split_picks in mseedutils\n:param pick_dir: directory outpur where phases are storaged\n:return:\n\"\"\"\n</code></pre> <p><code>PhasenetUtils.split_picks</code> <pre><code>@staticmethod\ndef save_original_picks(original_picks, original_p_dir):\n    \"\"\"\n\n    :param original_picks: picking output from phasenet (method split_picks in mseedutils)\n    :param original_p_dir: output to storage original_picks\n    :return:\n    \"\"\"\n</code></pre></p>"},{"location":"picker/#example-using-library","title":"Example using library","text":"<pre><code>import os\nfrom multiprocessing import freeze_support\nfrom surfquakecore.phasenet.phasenet_handler import PhasenetUtils\nfrom surfquakecore.phasenet.phasenet_handler import PhasenetISP\nfrom surfquakecore.project.surf_project import SurfProject\n\n### Set Paths to project file and output folder ###\npath_to_project = \"/Volumes/LaCie/test_surfquake_core/project/surfquake_project.pkl\"\noutput_picks = '/Volumes/LaCie/test_surfquake_core/test_picking'\n\nif __name__ == '__main__':\n    freeze_support()\n\n    # Load project\n    sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n\n    # Instantiate the class PhasenetISP\n    phISP = PhasenetISP(sp_loaded.project, amplitude=True, min_p_prob=0.90, min_s_prob=0.65)\n\n    # Running Stage\n    picks = phISP.phasenet()\n\n    \"\"\" PHASENET OUTPUT TO REAL INPUT \"\"\"\n\n    picks_results = PhasenetUtils.split_picks(picks)\n    PhasenetUtils.convert2real(picks_results, output_picks)\n    PhasenetUtils.save_original_picks(picks_results, output_picks)\n</code></pre>"},{"location":"project/","title":"Create your project","text":"<p>In surfQuake a project is simply a python object that can store in its attributes the path to valid seismogram files plus the associated metadata. This strategy allows to proceed with fast filters or join different projects. Project is the necessary input for the toolboxes Picker, Associator, Event Locator, Seismic Source and MTI.</p> <p>Here we will explain how the user can manage a project and be ready to proceed with the rest of toolboxes.</p>"},{"location":"project/#project-gui","title":"Project GUI","text":"<p>We start with the GUI. This is a screenshot of the Project GUI.</p> <p></p> <p>First, you need to choose between: </p> <ul> <li>Search files using Regular Expressions: Click in this button will open a window explorer to select the available files based on the filter edit line. In the example (.HHZ) and (EMUR*). Please set to blank space if you do not desire apply filters inside the window explorer. Then just select files and accept. The project will be automatically generated. </li> <li>Project Parth Files: This option is intendeed to let surfQuake search for valid seismogram files from a root folder in ahead. Optionally check Filter Time Spam and/or Filter Keys to include seismograms files that only fullfills the filter.</li> </ul> <p>Second:</p> <ul> <li>Save Project It is very remmendable to save the project. So, Proceed to give a name to the project and save it pressing Save Project for later using.</li> </ul> <p>Third:</p> <ul> <li>Load Project This action will open a window explorer so that you can select a project file previously saved and loaded. This will let you go ahead with the following toolboxes such as Picking Phases.</li> </ul> <p>Finally:</p> <ul> <li>Metadata (https://docs.obspy.org/tutorial/code_snippets/stationxml_file_from_scratch.html): Metadata file with the in there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal.</li> </ul> <p></p>"},{"location":"project/#project-from-cli","title":"Project from CLI","text":""},{"location":"project/#overview","title":"Overview","text":"<p>This command allows you to create a seismic project, which is essentially a dictionary storing the paths to seismogram files along with their corresponding metadata.</p>"},{"location":"project/#usage","title":"Usage","text":"<pre><code>&gt;&gt;surfquake project -d [path to data files] -s [path to save directory] -n [project name] --verbose\n</code></pre>"},{"location":"project/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake project -h\n</code></pre>"},{"location":"project/#create-project-example-from-cli","title":"Create Project example from CLI","text":"<p>In your termina, activate sufquake enviroment to have access to the commands. Then:</p> <pre><code>&gt;&gt; surfquake project -d /Volumes/LaCie/test_surfquake_core/testing_data -s /Volumes/LaCie/test_surfquake_core/testing_data/projects -n /surfquake_project_new.pkl --verbose\n</code></pre>"},{"location":"project/#project-from-library","title":"Project from library","text":""},{"location":"project/#classes","title":"Classes","text":"<p>In this section, we will explain the class SurfProject and we will explain how to manage your project from a simple example:</p> <p><code>SurfProject</code></p> <pre><code>class SurfProject:\n\n    def __init__(self, root_path: Union[str, List[str]]):\n\n        \"\"\"\n\n        SurfProject class is designed to be able to storage the path to seismograms\n        files plus the file metadata information (i.e. sampling_rate, starttime...)\n\n        Attributes:\n        - root_path (str): The root path to the folder where the user have the data files.\n\n        Methods:\n        - __init__(root_path): Initialize a new instance of MyClass.\n        - load_project(path_to_project_file: str): Load a project from a file storage in hard-drive\n        - save_project(path_file_to_storage: str): Saves a project as a pickle file in hard-drive\n        - search_files(verbose=True, **kwargs): Create a project. It can be used filters by nets,\n        stations, channels selection and/or filter by timestamp\n        - filter_project_keys(**kwargs): Filter a project (once is crated) using regular expressions.\n        \"\"\"\n</code></pre>"},{"location":"project/#methods","title":"Methods","text":"<p><code>search_files</code></p> <pre><code>    def search_files(self, format=\"NONE\", verbose=True, **kwargs):\n\n        \"\"\"\n        Args:\n\n        - verbose (bool): Description of arg1.\n        - nets (str): String with the name of selected nets to be filtered (i.e., \"WM,ES\")\n        - stations (str): String with the name of selected stations to be filtered (i.e., \"ARNO,UCM,EMAL\")\n        - channels (str): String with the name of selected channels to be filtered (i.e., \"HHN,HHZ,HHE\")\n        - starttime (str \"%Y-%m-%d %H:%M:%S\" ): String with the reference starttime, upper time spam threshold\n        (i.e.,\"2023-12-10 00:00:00\")\n        - endtime (str \"%Y-%m-%d %H:%M:%S\" ): String with the reference endtime, lower time spam threshold\n        (i.e.,\"2023-12-23 00:00:00\")\n\n        Returns:\n        - type: Description of the return value.\n        \"\"\"\n</code></pre> <p><code>filter_project_keys</code></p> <pre><code>    def filter_project_keys(self, **kwargs):\n\n        \"\"\"\n        Args:\n        - net (str): String with the name of selected nets to be filtered (i.e., \".\")\n        - station (str): String with the name of selected stations to be filtered (i.e., \"ARNO|UCM|EMAL\")\n        - channel (str): String with the name of selected channels to be filtered (i.e., \"HH.\")\n        \"\"\"\n</code></pre> <p><code>filter_project_time</code></p> <pre><code>    def filter_project_time(self, starttime: str, endtime: str):\n\n        \"\"\"\n        - starttime (str, \"%Y-%m-%d %H:%M:%S\"): String with the reference starttime, upper time spam threshold\n        (i.e., \"2023-12-10 00:00:00\")\n\n        - endtime (str, \"%Y-%m-%d %H:%M:%S\" ): String with the reference endtime, lower time spam threshold\n        (i.e., \"2023-12-23 00:00:00\")\n\n        \"\"\"\n</code></pre> <p><code>save_project</code></p> <pre><code>def save_project(self, path_file_to_storage: str)-&gt;bool\n# Saves the project object as a pickle file.\n</code></pre> <p><code>load_project</code></p> <pre><code>def load_project(path_to_project_file: str):\n</code></pre>"},{"location":"project/#attibutes","title":"Attibutes","text":"<pre><code>project :Dict\ndata_files :List\n</code></pre> <p>Next, the example of using this class and its methods. This example script is available in SurfQuakeCore/examples/manage_project_new.py</p> <pre><code>from multiprocessing import freeze_support\nfrom surfquakecore.project.surf_project import SurfProject\nimport time\n\npath_to_data = \"/Volumes/LaCie/test_surfquake_core/testing_data\"\npath_to_project = \"/Volumes/LaCie/test_surfquake_core/testing_data/projects/surfquake_project_new.pkl\"\n\nif __name__ == '__main__':\n\n    freeze_support()\n    sp = SurfProject(path_to_data)\n    #sp.search_files(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\", stations=\"SALF,VALC\", channels=\"HHZ\")\n    sp.search_files(verbose=False)\n    #sp_original_project = copy.copy()\n    sp.filter_project_keys(station=\"SALF|VALC|CEST\")\n    sp_original1 = sp.copy()\n    sp_original1.filter_project_keys(station=\"SALF\")\n    sp_original2 = sp.copy()\n    sp_original2.filter_project_keys(station=\"VALC\")\n\n    sp_join = sp_original1 + sp_original2\n    print(\"With no filter\")\n    print(sp_join)\n    sp_join.filter_project_time(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\")\n    print(\"With filter\")\n    print(sp_join)\n    sp_join.save_project(path_file_to_storage=path_to_project)\n    time.sleep(5)\n    sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n    print(sp_loaded)\n</code></pre> <p>The first step is create the object from the class SurfProject </p> <pre><code>sp = SurfProject\n</code></pre> <p>The necessary input to create the sp object is the root path where you have storage the seismogram files. Then, you can proceed to apply the method \"search_files\". This method includes the possibility of filter the inclusion of files inside the project.</p> <pre><code>sp.search_files(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\", stations=\"SALF,VALC\", channels=\"HHZ\")\nprint(sp) # To see the contain of the project\n</code></pre> <p>Additionally, once the project has been created, you can also filter it by using \u00b4regular expressions\u00b4 net, station, channel using:</p> <p>Note: some util Regex info at Wiki Regex and Python keywords <pre><code>sp.filter_project_keys(station=\"SALF|VALC|CEST\")\n</code></pre></p> <p>or filterintg the time spam using:</p> <pre><code>sp_join.ilter_project_time(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\")\n</code></pre> <p>Adding projects using \"+\" symbol</p> <pre><code>sp_original1 = sp.copy()\nsp_original1.filter_project_keys(station=\"SALF\")\nsp_original2 = sp.copy()\nsp_original2.filter_project_keys(station=\"VALC\")\n\nsp_join = sp_original1 + sp_original2\n</code></pre> <p>Finally, you can save the project by, <pre><code>sp_join.save_project(path_file_to_storage=path_to_project)\n</code></pre> and loading it</p> <pre><code>sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n</code></pre>"},{"location":"source/","title":"Source Parameters","text":"<p>The tool Source Parameters is designed to estimate events source parameters (i.e., Mw, ML, seismic moment, corner frequency, radiated energy, source size and stress drop) and the attenuation parameters (t-star, quality factor). It is based in the implementation of Satrinano et al., 2023. A detailed theoretical background can be found here</p>"},{"location":"source/#source-parameters-gui","title":"Source Parameters GUI","text":"<ul> <li>Time Window Parameters<ul> <li>P- and S-wave tolerance: Difference in seconds from the detected wave and the theroretical arrival time.</li> <li>noise_pre_time window: Window lenght before the first arrival time</li> <li>signal window: Window leght of signal to be analyse after first phase arrival time</li> <li>spectral window: Time window before the first arrival time</li> </ul> </li> <li>Source Parameters<ul> <li>Source Density: Density of the rock in the source.</li> <li>rpp: Radiation pattern coefficient for the P-wave</li> <li>rps: Radiation pattern coefficient for the S-wave</li> <li>Geometrical Spreading Correction: Spectra will be multiplied by this value to correct for the lost amplitude<ul> <li>r_power_n: geom_spread_n_exponent = 1 (default, body wave in a homogeneous full-space), 0.5 (surface wave in a homogeneous half-space)</li> <li>boatwright: \"r\" (body waves) geometrical spreading for hypocentral distances below a cutoff distance; frequency-dependent geometrical spreading above the cutoff distance (Boatwright et al., 2002).<ul> <li>Geometrical spreading cutoff distance: Geometrical spreading cutoff distance, in km, for the \"boatwright\" model</li> </ul> </li> </ul> </li> </ul> </li> <li>Local Magnitude: Local magnitude parameters: ml = log10(A) + a * log10(R/100) + b * (R-100) + c, where A is the maximum W-A amplitude (in mm) and R is the hypocentral distance (in km)</li> </ul>"},{"location":"source/#config-file","title":"Config file","text":"<pre><code># Config file for source_spec\n\n# GENERAL PARAMETERS --------\n# All the fields are optional.\n# The filled in fields will be written to output files.\n# Author information\nauthor_name = string(default=None)\nauthor_email = string(default=None)\n# Agency information\nagency_full_name = string(default=None)\nagency_short_name = string(default=None)\nagency_url = string(default=None)\n# the logo can be a local file (it will be copied to the output dir)\n# or a URL\nagency_logo = string(default=None)\n# -------- GENERAL PARAMETERS\n\n# TRACE AND METADATA PARAMETERS --------\n# Channel naming for mis-oriented channels (vertical, horiz1, horiz2):\n# Example:\n#   mis_oriented_channels = Z,1,2\nmis_oriented_channels = string_list(default=None)\n\n# Option to specify non standard instrument codes (e.g., \"L\" for accelerometer)\ninstrument_code_acceleration = string(default=None)\ninstrument_code_velocity = string(default=None)\n\n# For more complex network.station.location.channel (SCNL) naming scenarios,\n# you can provide a file, in json format, with traceid (SCNL) mapping\ntraceid_mapping_file = string(default=None)\n\n# List of traceids to ignore.\n# Use network.station.location.channel; wildcards are accepted\n# Example:\n#   ignore_traceids = FR.CIEL.*.*, AM.RA0D3.00.*\nignore_traceids = force_list(default=None)\n\n# List of traceids to use.\n# Use network.station.location.channel; wildcards are accepted\n# Example:\n#   use_traceids = FR.CIEL.*.*, AM.RA0D3.00.*\nuse_traceids = force_list(default=None)\n\n# Maximum epicentral distance (km) to process a trace\nmax_epi_dist = float(min=0, default=None)\n\n# Directory or single file name containing station metadata\n# (instrument response and station coordinates).\n# Note: this parameter can be overridden by the command line option\n#       with the same name.\n# Station metadata files can be in one of the following formats:\n#   StationXML, dataless SEED, SEED RESP, PAZ (SAC polezero format)\n# Notes:\n# 1. SourceSpec will not enter in subdirectories of the given directory\n#    (only one level allowed)\n# 2. Traceid for PAZ files is specified through their name.\n#    The traceid (network.station.location.channel) must be in the last four\n#    fields (separated by a dot \".\") before the file suffix (which can be\n#    \".paz\", \".pz\", or no suffix).\n#    Example:\n#      PREFIX.NET.STA.LOC.CHAN.paz\n#    or (no prefix):\n#      NET.STA.LOC.CHAN.paz\n#    or (no prefix and no suffix):\n#      NET.STA.LOC.CHAN\n# 3. If no traceid is specified through the PAZ file name, then it is assumed\n#    that this is a generic PAZ, valid for all the stations that do not have\n#    a specific PAZ. Use \"trace_units\" below to specify the units of the\n#    generic PAZ.\n# 4. SEED RESP and PAZ files do not contain station coordinates, which\n#    should therefore be in the trace header (traces in SAC format)\nstation_metadata = string(default=None)\n\n# It is also possible to provide a constant sensitivity (i.e., flat instrument\n# response curve) as a numerical value or a combination of SAC header fields\n# (in this case, traces must be in SAC format).\n# This parameter overrides the response curve computed from station_metadata.\n# Leave it to None to compute instrument response from station_metadata.\n# Examples:\n#  sensitivity = 1\n#  sensitivity = 1e3\n#  sensitivity = resp0\n#  sensitivity = resp1*resp2\n#  sensitivity = user3/user2\nsensitivity = string(default=None)\n\n# SQLite database file for storing output parameters (optional):\ndatabase_file = string(default=None)\n\n# Correct_instrumental_response (optional, default=True):\ncorrect_instrumental_response = boolean(default=True)\n\n# Trace units.\n# Leave it to 'auto' to let the code decide, based on instrument type.\n# Manually set it to 'disp', 'vel' or 'acc' if you have already preprocessed\n# the traces.\ntrace_units = option('auto', 'disp', 'vel', 'acc', default='auto')\n# -------- TRACE AND METADATA PARAMETERS\n\n\n# TIME WINDOW PARAMETERS --------\n# P and S wave velocity (in km/s) for travel time calculation\n# (if None, the global velocity model 'iasp91' is used)\n# Theoretical P or S arrival times are used when a manual P or S pick is not\n# available, or when the manual P or S pick is too different from the\n# theoretical arrival (see 'p_arrival_tolerance' and 's_arrival_tolerance'\n# below).\nvp_tt = float(min=0, default=None)\nvs_tt = float(min=0, default=None)\n# As an alternative, a directory containing NonLinLoc travel time grids\n# can be specified and values defined above will be ignored.\n# Note that reading NonLinLoc grids takes time. For simple 1D models, you\n# can speed up considerably the process using a generic station\n# named \"DEFAULT\". The coordinates of this default station are not important,\n# since they will be superseded by each station's coordinates.\nNLL_time_dir = string(default=None)\n\n# Arrival tolerances (in seconds) to accept a manual P or S pick\np_arrival_tolerance = float(min=0, default=4.0)\ns_arrival_tolerance = float(min=0, default=4.0)\n\n# Start time (in seconds) of the noise window, respect to the P arrival time\nnoise_pre_time = float(default=6.0)\n\n# Start time (in seconds) of the signal window, respect to the P or S arrival\n# times (see \"wave_type\" below)\nsignal_pre_time = float(default=1.0)\n\n# Length (in seconds) for both noise and signal windows\nwin_length = float(min=0, default=5.0)\n# -------- TIME WINDOW PARAMETERS\n\n\n# SPECTRUM PARAMETERS --------\n# Wave type to analyse: 'P', 'S', 'SH' or 'SV'\n# If 'SH' or 'SV' are selected, traces are rotated in the radial-transverse\n# system. Transverse component is used for 'SH', radial component (and\n# optionally the vertical component, see 'ignore_vertical' below) is used\n# for 'SV'\nwave_type = option('P', 'S', 'SH', 'SV', default='S')\n\n# Integrate in time domain (default: integration in spectral domain)\ntime_domain_int = boolean(default=False)\n\n# Ignore vertical components when building S or SV spectra\n# Note: this option has no effect when 'wave_type' is 'P' (the vertical\n# component is not ignored) and when 'wave_type' is 'SH' (the vertical\n# component is not needed)\nignore_vertical = boolean(default=False)\n\n# Taper half width: between 0 (no taper) and 0.5\ntaper_halfwidth = float(min=0, max=0.5, default=0.05)\n\n# Spectral window length (seconds)\n# Signal is tapered, and then zero padded to\n# this window length, so that the spectral\n# sampling is fixed to 1/spectral_win_length.\n# Comment out (or set to None) to use\n# signal window as spectral window length.\nspectral_win_length = float(min=1e-99, default=None)\n\n# Spectral smoothing window width in frequency decades\n# (i.e., log10 frequency scale).\n# Example:\n#  spectral_smooth_width_decades=1 means a width of 1 decade\n#  (generally, too large, producing a spectrum which is too smooth).\n#  spectrum(f0) is smoothed using values between f1 and f2, so that\n#  log10(f1)=log10(f0)-0.5 and log10(f2)=log10(f0)+0.5\n#    i.e.,\n#  f1=f0/(10^0.5) and f2=f0*(10^0.5)\n#    or,\n#  f2/f1=10 (1 decade width)\n# Default value of 0.2 is generally a good choice\nspectral_smooth_width_decades = float(min=1e-99, default=0.2)\n\n# Residuals file path\n# (a pickle file with the mean residuals per station,\n# used for station correction):\nresiduals_filepath = string(default=None)\n\n# Remove the signal baseline after instrument correction and before filtering\nremove_baseline = boolean(default=False)\n\n# Band-pass frequencies (Hz) for accelerometers, velocimeters\n# and displacement sensors.\n# Use bp_freqmin_STATION and bp_freqmax_STATION to provide\n# filter frequencies for a specific STATION code.\n# TODO: calculate from sampling rate?\nbp_freqmin_acc    = float(min=0, default=1.0)\nbp_freqmax_acc    = float(min=0, default=50.0)\nbp_freqmin_shortp = float(min=0, default=1.0)\nbp_freqmax_shortp = float(min=0, default=40.0)\nbp_freqmin_broadb = float(min=0, default=0.5)\nbp_freqmax_broadb = float(min=0, default=40.0)\nbp_freqmin_disp   = float(min=0, default=0.5)\nbp_freqmax_disp   = float(min=0, default=40.0)\n\n# Spectral windowing frequencies (Hz) for accelerometers, velocimeters\n# and displacement sensors.\n# (spectra will be cut between these two frequencies)\n# Use freq1_STATION and freq2_STATION to provide\n# windowing frequencies for a specific STATION code.\nfreq1_acc     = float(min=0, default=1.0)\nfreq2_acc     = float(min=0, default=30.0)\nfreq1_shortp  = float(min=0, default=1.0)\nfreq2_shortp  = float(min=0, default=30.0)\nfreq1_broadb  = float(min=0, default=0.5)\nfreq2_broadb  = float(min=0, default=30.0)\nfreq1_disp    = float(min=0, default=0.5)\nfreq2_disp    = float(min=0, default=30.0)\n# -------- SPECTRUM PARAMETERS\n\n\n# SIGNAL/NOISE PARAMETERS --------\n# Minimum rms (in trace units before instrument corrections)\n# to consider a trace as noise\nrmsmin = float(min=0, default=0)\n\n# Time domain S/N ratio min\nsn_min = float(min=0, default=0)\n\n# Clipping detection algorithm\n# Options:\n#  - 'none': no clipping detection\n#  - 'clipping_score': compute a clipping score for each trace, based on the\n#    shape of the kernel density estimation of the trace amplitude values.\n#    A high clipping score will be obtained for traces with a high number of\n#    samples whose amplitude is close to the trace highest or lowest\n#    amplitude values. Clipping scores for each trace are printed on the\n#    terminal and in the log file.\n#    Note: if \"remove_baseline\" is True (see above), clipping scores are\n#    computed on the baseline-corrected signal.\n#  - 'clipping_peaks': count the number of peaks in the kernel density\n#    estimation of the trace amplitude values. The trace is considered clipped\n#    if at least one peak is found within the trace highest or lowest amplitude\n#    values. Kernel density peaks for each trace are printed on the terminal\n#    and in the log file.\nclipping_detection_algorithm = option('none', 'clipping_score', 'clipping_peaks', default='clipping_score')\n# Plot a debug figure for each trace with the results of the clipping algorithm\n# Note: the figures are always shown, even if \"plot_show\" is False (see below)\nclipping_debug_plot = boolean(default=False)\n# Threshold for the 'clipping_score' algorithm (between 0 and 100).\n# A value of 100 means no clipping detection.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_score'.\nclipping_score_threshold = float(min=0, max=100, default=10)\n# Sensitivity for the 'clipping_peaks' algorithm (between 1 and 5).\n# Higher values mean more peaks are detected.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_peaks'.\nclipping_peaks_sensitivity = integer(min=1, max=5, default=3)\n# Trace amplitude percentile for the 'clipping_peaks' algorithm (between 0\n# and 100). Example:\n#   clipping_peaks_percentile = 10\n# means that the 10% highest and lowest values of the trace amplitude will be\n# checked for clipping.\n# A value of 0 means that no clipping check will be performed.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_peaks'.\nclipping_peaks_percentile = float(min=0, max=100, default=10)\n\n# Maximum gap length for the whole trace, in seconds\ngap_max = float(min=0, default=None)\n# Maximum overlap length for the whole trace, in seconds\noverlap_max = float(min=0, default=None)\n\n# Spectral S/N ratio min, below which a spectrum will be skipped\nspectral_sn_min = float(min=0, default=0)\n# Frequency range (Hz) to compute the spectral S/N ratio\n# (comment out or use None to indicate the whole frequency range)\n# Example:\n#  spectral_sn_freq_range = 0.1, 2\nspectral_sn_freq_range = float_list(min=0, default=None)\n# -------- SIGNAL/NOISE PARAMETERS\n\n\n# SPECTRAL MODEL PARAMETERS --------\n# P and S wave velocity close to the source (km/s)\nvp_source = float(min=0, default=5.5)\nvs_source = float(min=0, default=3.2)\n# P and S wave velocity close to the stations (km/s)\n# If set to None, velocity values close to the source will be used\nvp_stations = float(min=0, default=None)\nvs_stations = float(min=0, default=None)\n# Note: if both v(p,s)_source and v(p,s)_stations are set to None, then\n# velocities will be extracted from the global velocity model 'iasp91'\n# As an alternative, a directory containing a NonLinLoc model can be specified\n# In this case, the values provided above will be ignored\nNLL_model_dir = string(default=None)\n# Density (kg/m3):\nrho = float(min=0, default=2500)\n# P-wave average radiation pattern coefficient:\nrpp = float(min=0, default=0.52)\n# S-wave average radiation pattern coefficient:\nrps = float(min=0, default=0.62)\n# Radiation pattern from focal mechanism, if available\nrp_from_focal_mechanism = boolean(default=False)\n# Geometrical spreading correction of wave amplitude.\n# Spectra will be multiplied by this value to correct for the lost amplitude.\n# Possible options are:\n#    'r_power_n':  \"r\" to the power of \"n\" (r\u207f).\n#                  You must provide the value of the exponent \"n\"\n#                  (see \"geom_spread_n_exponent\" below).\n#    'boatwright': \"r\" (body waves) geometrical spreading for hypocentral\n#                  distances below a cutoff distance; frequency-dependent\n#                  geometrical spreading above the cutoff distance (Boatwright\n#                  et al., 2002). You must provide the cutoff distance (see\n#                  \"geom_spread_cutoff_distance\" below).\ngeom_spread_model = option('r_power_n', 'boatwright', default='r_power_n')\n# Exponent \"n\" for the \"r_power_n\" geometrical spreading coefficient (positive\n# float). Examples:\n#   geom_spread_n_exponent = 1 (default, body wave in a homogeneous full-space)\n#   geom_spread_n_exponent = 0.5 (surface wave in a homogeneous half-space)\ngeom_spread_n_exponent = float(min=0, default=1)\n# Geometrical spreading cutoff distance, in km, for the \"boatwright\" model:\ngeom_spread_cutoff_distance = float(min=0, default=100)\n# -------- SPECTRAL MODEL PARAMETERS\n\n\n# INVERSION PARAMETERS --------\n# Weighting type: 'noise', 'frequency' or 'no_weight'\nweighting = option('noise', 'frequency', 'no_weight', default='noise')\n# Parameters for 'frequency' weighting (ignored for 'noise' weighting):\n#   weight for f&lt;=f_weight (Hz)\n#   1      for f&gt; f_weight (Hz)\nf_weight = float(min=0, default=7.)\nweight = float(min=0, default=10.)\n\n# Initial value for t_star (seconds)\nt_star_0 = float(default=0.045)\n# Try to invert for t_star_0.\n# If the inverted t_star_0 is non-positive, then fixed t_star_0 will be used\ninvert_t_star_0 = boolean(default=False)\n# Allowed variability around inverted t_star_0 in the main inversion\n# (expressed as a fraction of t_star_0, between 0 and 1).\n# If the inverted t_star_0 is non-positive, then t_star_min_max is used\n# (see below).\nt_star_0_variability = float(min=0, default=0.1)\n# Inversion algorithm:\n# TNC: truncated Newton algorithm (with bounds)\n# LM: Levenberg-Marquardt algorithm\n# (warning: Trust Region Reflective algorithm will be used instead if\n#  bounds are provided)\n# BH: basin-hopping algorithm\n# GS: grid search\n# IS: importance sampling of misfit grid, using k-d tree\ninv_algorithm = option('TNC', 'LM', 'BH', 'GS', 'IS', default='TNC')\n# Parameter bounds:\n# Notes:\n# 1. Mw bounds are autoset between 0.9*min(Mw(f)) and 1.1*max(Mw(f)),\n#    where Mw(f) is the low frequency spectral plateau in magnitude units.\n#    If noise weighting is used, frequencies for which S/N(f) &lt; 0.5*max(S/N(f))\n#    will be ignored, where S/N(f) is the spectral signal to noise ratio.\n# 2. If not specified, fc bounds will be autoset to fc0/10 and fc0*10, i.e. two\n#    decades around fc0. The value of fc0 is set as the first maximum of\n#    spectral S/N (noise weighting), or at \"f_weight\" (frequency weighting),\n#    or at half of the frequency window (no weighting)\n# 3. Specify bounds as a list, ex.:\n#      fc_min_max = 0.1, 40\n#    (comment out or use None to indicate no bound)\nfc_min_max = float_list(min=0, default=None)\n# t_star_min_max does not supersede t_star_0_variability\nt_star_min_max = float_list(default=list(0.001, 0.25))\n# optional : Qo bounds (converted into t_star bounds in the code).\n# (comment out or use None to indicate no bound)\n# Note: if you want to explore negative t_star values, you have to specify\n# -Qo_min, Qo_min. This because t_star is proportional to 1/Qo.\n# Example, for searching only positive t_star values:\n#   Qo_min_max = 10, 1000\n# If you want to search also negative t_star values:\n#   Qo_min_max = -10, 10\nQo_min_max = float_list(default=None)\n# -------- INVERSION PARAMETERS\n\n# POST-INVERSION PARAMETERS --------\n# Post-inversion bounds: use this bounds to reject certain inversion\n# results, per station.\n# Sometimes it is better to be more permissive with inversion parameters and\n# reject \"bad\" solutions after the inversion, rather than forcing the\n# inversion to converge within strict bounds.\n# fc bounds, in Hz\npi_fc_min_max = float_list(min=0, default=None)\n# t_star bounds, in s\npi_t_star_min_max = float_list(default=None)\n# Brune stress drop bounds, in MPa\npi_bsd_min_max = float_list(min=0, default=None)\n# Maximum acceptable misfit between inverted and observed spectrum\npi_misfit_max = float(min=0, default=None)\n# -------- POST-INVERSION PARAMETERS\n\n\n# RADIATED-ENERGY PARAMETERS --------\n# Maximum frequency (Hz) to measure radiated energy Er\n# (above this frequency, the finite-band correction\n# of Di Bona &amp; Rovelli, 1988, will be applied)\nmax_freq_Er = float(min=0, default=None)\n# -------- RADIATED-ENERGY PARAMETERS\n\n\n# LOCAL MAGNITUDE PARAMETERS --------\ncompute_local_magnitude = boolean(default=False)\n# Local magnitude parameters:\n#   ml = log10(A) + a * log10(R/100) + b * (R-100) + c\n# where A is the maximum W-A amplitude (in mm)\n# and R is the hypocentral distance (in km)\n# Default values (for California) are:\n#   a = 1., b = 0.00301, c = 3.\na = float(default=1.)\nb = float(default=0.00301)\nc = float(default=3.)\n# Band-pass filtering frequencies (Hz) for local magnitude\nml_bp_freqmin = float(min=0, default=0.1)\nml_bp_freqmax = float(min=0, default=20.0)\n# -------- LOCAL MAGNITUDE PARAMETERS\n\n\n# SUMMARY STATISTICS PARAMETERS --------\n# For each spectral parameter, SourceSpec computes three different summary\n# estimates (from station estimates), using the following statistics:\n#  - mean\n#  - weighted_mean\n#  - percentiles\n# All the three summary estimates are stored in the YAML and SQLite output,\n# but only a reference one is used for map plots, QuakeML and HYPO output,\n# as well as for the \"Event Summary\" section in HTML report and for computing\n# station spectral residuals.\n# Use the parameter \"reference_statistics\" to specify the reference summary\n# statistics that will be used in the cases described above.\nreference_statistics = option('mean', 'weighted_mean', 'percentiles', default='weighted_mean')\n# Number of sigmas (standard deviations) for average and weighted average\n# uncertainty estimation\nn_sigma = float(min=0.1, max=10, default=1)\n# Percentage levels to compute lower, mid and upper percentiles\n#   Example: to mimic a Gaussian distribution (one-sigma, 68.2% confidence):\n#       lower_percentage = 15.9\n#       mid_percentage = 50\n#       upper_percentage = 84.1\n# Note: the confidence level is upper_percentage - lower_percentage\nlower_percentage = float(min=0, max=100, default=15.9)\nmid_percentage = float(min=0, max=100, default=50)\nupper_percentage = float(min=0, max=100, default=84.1)\n# Reject outliers before computing means (standard and weighted),\n# using the IQR method.\n# IQR is the interquartile range Q3-Q1, where Q1 is the 25% percentile\n# and Q3 is the 75% percentile.\n# Values that are smaller than (Q1 - nIQR*IQR) or larger than (Q3 + nIQR*IQR)\n# will be rejected as outliers.\n# Set nIQR to None to disable outlier rejection.\n# Note: this parameter also controls the position of \"whiskers\" on the source\n# parameter box plots.\nnIQR = float(min=0, default=1.5)\n# -------- SUMMARY STATISTICS PARAMETERS\n\n\n# PLOT PARAMETERS --------\n# Show interactive plots (slower)\nplot_show = boolean(default=False)\n# Save plots to disk\nplot_save = boolean(default=True)\n# Plot file format: 'png', 'pdf', 'pdf_multipage' or 'svg'\nplot_save_format = option('png', 'pdf', 'pdf_multipage', 'svg', default='png')\n# Plots an extra synthetic spectrum with no attenuation\nplot_spectra_no_attenuation = boolean(default=False)\n# Plots an extra synthetic spectrum with no fc\nplot_spectra_no_fc = boolean(default=False)\n# Max number of rows in plots\nplot_spectra_maxrows = integer(min=1, default=3)\nplot_traces_maxrows = integer(min=1, default=3)\n# Plot ignored traces (clipped or low S/N)\nplot_traces_ignored = boolean(default=True)\n# Plot ignored spectra (low S/N)\nplot_spectra_ignored = boolean(default=True)\n# Plot station map\nplot_station_map = boolean(default=False)\n# Plot station names on map\nplot_station_names_on_map = boolean(default=False)\n# Text size for station names\nplot_station_text_size = float(min=0, default=8)\n# Coastline resolution\n# Use None to let the code autoset the coastline resolution.\n# Otherwise choose one of: 'full', 'high', 'intermediate', 'low' or 'crude'\nplot_coastline_resolution = option('full', 'high', 'intermediate', 'low', 'crude', default=None)\n# Zoom level for map tiles\n# Use None to let the code autoset the zoom level\n# Otherwise choose an integer between 1 (minimum zoom) and 18 (maximum zoom)\n# Note: for zoom levels larger than 11, some map tiles could be missing\nplot_map_tiles_zoom_level = integer(min=1, max=18, default=None)\n# -------- PLOT PARAMETERS\n\n\n# HTML REPORT --------\n# Generate an HTML page summarizing the results of this run\n# Note: \"plot_save_format\" (above) must be \"png\" or \"svg\"\nhtml_report = boolean(default=False)\n# Link to event page. If set, the event ID on the HTML page will be a link to\n# the event page. Use $EVENTID to indicate the current event ID.\n# Example:\n#   event_url = https://earthquake.usgs.gov/earthquakes/eventpage/$EVENTID/executive\nevent_url = string(default=None)\n# -------- HTML REPORT\n\n\n# QUAKEML PARAMETERS ----------------\n# Parameters for QuakeML output.\n#\n# A QuakeML file will be generated only if QuakeML is used for input.\n# The output file will be based on the input file, with additional information\n# on seismic moment, Mw and source parameters computed by SourceSpec.\n# Note: if you don't understand the parameters below, then probably you\n# don't need QuakeML output and you can leave all the parameters to their\n# default value\n\n# Set SourceSpec Mw as preferred\nset_preferred_magnitude = boolean(default=False)\n# Base for all the object ids (smi)\nsmi_base = string(default=\"smi:local\")\n# String to strip from the Origin id when constructing the\n# Magnitude and stationMagnitude ids.\nsmi_strip_from_origin_id = string(default=\"\")\n# Template for the Magnitude object id (smi).\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_magnitude_template = string(default=\"$SMI_BASE/Magnitude/Origin/$ORIGIN_ID#sourcespec\")\n# Template for the stationMagnitude object id (smi).\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\n# Use $SMI_MAGNITUDE_TEMPLATE to reuse the template for Magnitude object\n# Use $WAVEFORM_ID to indicate the id of the associated waveform.\nsmi_station_magnitude_template = string(default=\"$SMI_MAGNITUDE_TEMPLATE#$WAVEFORM_ID\")\n# Template for the MomentTensor object id (smi) which is used to store\n# the scalar moment value.\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_moment_tensor_template = string(default=\"$SMI_BASE/MomentTensor/Origin/$ORIGIN_ID#sourcespec\")\n# Template for the FocalMechanism object id (smi) which is used to store\n# the scalar moment value.\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_focal_mechanism_template = string(default=\"$SMI_BASE/FocalMechanism/Origin/$ORIGIN_ID#sourcespec\")\n# -----------------QUAKEML PARAMETERS\n</code></pre>"},{"location":"source/#source-parameters-from-cli","title":"Source Parameters from CLI","text":""},{"location":"source/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake source parameters estimation [-h] -i INVENTORY_FILE_PATH -p PROJECT_FILE_PATH -c CONFIG_FILE_PATH -l LOC_FILES_PATH [-t] -o OUTPUT_DIR_PATH\n</code></pre>"},{"location":"source/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake source -h\n</code></pre> <pre><code>&gt;&gt; surfquake source -i /surfquake_test/metadata/inv_all.xml -p /surfquake_test/project/surfquake_project.pkl -c /surfquake_test/config_files/source_spec.conf -l /surfquake_test/test_nll_final/loc -o /surfquake_test/test_source_final\n</code></pre>"},{"location":"source/#source-parameters-from-library","title":"Source Parameters from Library","text":""},{"location":"source/#classes","title":"Classes","text":"<p><code>Automag</code></p> <pre><code>class Automag:\n\n    def __init__(self, project: SurfProject, locations_directory: str, inventory_path, source_config: str,\n                 output_directory: str, scale: str, gui_mod=None):\n\n        \"\"\"\n        Manage SourceSpec program to estimate source parameters.\n        :param project: SurfProject object.\n        :param inventory_path: Path to metadata file.\n        :param source_config: Path to source config file.\n        :param output_directory: Path to output folder.\n        :param scale: if regional waveforms will cut with small adapted time windows, else will be cut with a \n        long time window\n        \"\"\"\n</code></pre> <p><code>ReadSource</code> <pre><code>class ReadSource:\n    def __init__(self, root_path_to_output: str):\n        \"\"\"\n        The class methods are designed to scan the output of sourcespec\n        root_path_to_output: Root path where sourcespec output is expected\n        \"\"\"\n        self.root_path_to_output = root_path_to_output\n        self.obsfiles = []\n</code></pre></p>"},{"location":"source/#methods","title":"Methods","text":"<p><code>estimate_source_parameters</code> <pre><code># Automag instance method\ndef estimate_source_parameters(self):\n    # Loop over loc folder files and run source parameters estimation\n</code></pre></p> <p><code>generate_source_summary</code> <pre><code># ReadSource instance method\ndef generate_source_summary(self):\n\n    \"\"\"\n    # Generate source parameters summary as dataframe\n    :return List: List of dictionaries containing source parameters\n    \"\"\"\n</code></pre></p> <p><code>write_summary</code> <pre><code># ReadSource instance method\ndef write_summary(self, summary: list, summary_path: str):\n    \"\"\"\n    Transform the summary into txt file using Pandas Dataframe\n    :param summary: List of dictionaries containing source parameters\n    :param summary_path: path to file output including the name of the file.\n    \"\"\"\n</code></pre></p>"},{"location":"source/#example-using-library","title":"Example using library","text":"<pre><code>from surfquakecore.magnitudes.run_magnitudes import Automag\nfrom surfquakecore.magnitudes.source_tools import ReadSource\nfrom surfquakecore.project.surf_project import SurfProject\nimport os\n\nif __name__ == \"__main__\":\n\n    cwd = os.path.dirname(__file__)\n    ## Project definition ##\n    path_to_project = \"/test_surfquake_core/project\"\n    project_path_file = os.path.join(path_to_project, \"surfquake_project.pkl\")\n    print(\"project:\", project_path_file)\n\n    # load the project\n    sp_loaded = SurfProject.load_project(path_to_project_file=project_path_file)\n    print(sp_loaded)\n\n    # Basic input: working_directory, inventory file path and config_file input\n    working_directory = os.path.join(cwd, \"source_estimations\")\n    inventory_path = os.path.join(working_directory, \"inventories\", \"inv_surfquakecore.xml\")\n    path_to_configfiles = os.path.join(working_directory, \"config/source_spec.conf\")\n    locations_directory = os.path.join(working_directory, \"locations\")\n    output_directory = os.path.join(working_directory, \"output\")\n    summary_path = '/Users/roberto/Documents/SurfQuakeCore/examples/source_estimations/source_summary.txt'\n\n    # Running stage\n    mg = Automag(sp_loaded, locations_directory, inventory_path, path_to_configfiles, output_directory, \"regional\")\n    mg.estimate_source_parameters()\n\n    # Now we can read the output and even write a txt summarizing the results\n    rs = ReadSource(output_directory)\n    summary = rs.generate_source_summary()\n    rs.write_summary(summary, summary_path)\n</code></pre>"}]}