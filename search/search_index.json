{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to","text":"<p>SurfQuake has been designed to streamline the workflow of estimating seismic source parameters. Comprehensive set of toolboxes automates the determination of arrival times, event locations, event magnitudes , attenuation, and moment tensor inversion. The software is programmed in Python 3 and offers the users the possibility of three programming levels for flexibility and customization.</p> <ul> <li> <p>The Core Library  allows users to integrate the core of surfQuake into their preexisting scripts, giving advanced users full control.</p> </li> <li> <p>The Command Line Interface  gives users access to an upper layer that simplifies the use of the core, enabling task execution through simple commands.</p> </li> <li> <p>The Graphical User Interface (GUI): Wraps the SurfQuake core in a user-friendly interface, making it accessible to users who prefer visual interaction. The GUI is connected to a SQLite database to store all results, ensuring easy retrieval and management of data.</p> </li> </ul>"},{"location":"#news","title":"News","text":"<ul> <li> <p>Seismological Research Letters paper</p> </li> <li> <p>Expected release in july surfquake v0.0.9, see mass processing</p> </li> </ul> Links Grid See surfQuake open-source core code Follow us on Twitter Subscribe on YouTube Questions and Issues Subscribe to news and future workshops"},{"location":"#toolboxes","title":"ToolBoxes","text":"<ul> <li>Create your Project </li> <li>Phase Picker </li> <li>Event Associator </li> <li>Event Location </li> <li>Source Parameters </li> <li>Moment Tensor Inversion </li> <li>Data Base </li> <li>Utils </li> </ul>"},{"location":"#how-to-follow-surfquake-tutorial","title":"How to follow surfQuake Tutorial","text":"<p>The first step is to select which programming level is the most convenient for you. SurfQuake is divided into five Toolboxes: Picking, Association, Locate, Source, and Moment Tensor Inversion (MTI). Each toolbox link below contains a description of the software according to your programming level and an example.</p> <p>Let's start with Project  and then continue with the next toolboxes.</p>"},{"location":"#case-of-study-and-supporting-materials","title":"Case of Study and Supporting Materials","text":"<p>First: Case of study, contains a full example of using surfQuake with core Library Python scripts, Core Library bash script and expected results. Of course you can try to run the example using the GUI.</p> <p>Second: Earth Velocity models examples. Event Location format and MTI format.</p>"},{"location":"#cite-surfquake","title":"Cite surfQuake:","text":"<p>Cabieces, R., Junqueira, T. C., Harris, K., Relinque, J., Satriano, C. &amp; Vack\u00e1\u0159, J: SurfQuake: A new Python toolbox for the workflow process of seismic sources, Seismological Research Letters, may 2025.</p>"},{"location":"associate/","title":"Arraival times Assocotiation","text":"<p>The main goal of this tool is to associate the arrival times of different P- and S-waves to the their corresponding events. The associator algorythm used in surfquake is REAL (Zhang et al., 2019). The user needs to set the input parameters and point to the folder where the picks have been storaged. In th following sections it will be describe the surfquake imprementation of REAL, for a full description of the parameters visit REAL cookbook</p>"},{"location":"associate/#events-associator-gui","title":"Events Associator GUI","text":"<p>This is a screenshot of the Associator GUI.</p> <p></p> <p>The basics settings to associate inside a medium size region (300 x 300) km are show in the upper screenshot.</p> <ul> <li>Picking Directory: Root path to the folders containing the picking files. This files are automatically generated after running the picking tool.</li> <li> <p>Output Directory: Path to the forlder where the users wants the results of the arrival times association. Picking file nll_input.txt to Event Locaion tool will be also saved in this folder.</p> </li> <li> <p>Geographic Framework: Set the coordinates of your study region and remind loading the metadata from project tool. You can plot a map to be sure tour settings are ok.</p> </li> <li>Associator Parameters: These parameters are described in this link.</li> </ul>"},{"location":"associate/#config-files","title":"Config files","text":"<p>The parametrization of the Event Assocciator tool can be storaged in a file.ini. An example of this file is as follows:</p> <pre><code>[GEOGRAPHIC_FRAME]\nLAT_REF_MAX = 43.0000\nLAT_REF_MIN = 42.0000\nLON_REF_MIN = 0.8000\nLON_REF_MAX = 2.2000\nDEPTH = 20.00\n#\n[GRID_SEARCH_PARAMETERS]\nHORIZONTAL_SEARCH_RANGE = 4.80\nDEPTH_SEARCH_RANGE = 50.00\nEVENT_TIME_WINDOW = 120.00\nHORIZONTAL_SEARCH_GRID_SIZE = 0.60\nDEPTH_SEARCH_GRID_SIZE = 10.00\n#\n[TRAVEL_TIME_GRID_SEARCH]\nHORIZONTAL_RANGE = 5.00\nDEPTH_RANGE = 50.00\nDEPTH_GRID_RESOLUTION_SIZE = 2.00\nHORIZONTAL_GRID_RESOLUTION_SIZE = 0.01\n#\n[THRESHOLD_PICKS]\nMIN_NUM_P_WAVE_PICKS = 3\nMIN_NUM_S_WAVE_PICKS = 1\nNUM_STATIONS_RECORDED = 1\n</code></pre>"},{"location":"associate/#events-associator-from-cli","title":"Events Associator from CLI","text":""},{"location":"associate/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake associator [-h] -i INVENTORY_FILE_PATH -p DATA_DIR -c CONFIG_FILE_PATH -w WORK_DIR_PATH -s SAVE_DIR [-v]\n</code></pre>"},{"location":"associate/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake associator -h\n</code></pre>"},{"location":"associate/#run-phase-picker-from-cli","title":"Run Phase Picker from CLI","text":"<pre><code>&gt;&gt; surfquake associate -i /surfquake_test/metadata/inv_all.xml -p /surfquake_test/test_picking_final -c /surfquake_test/config_files/real_config.ini\n</code></pre>"},{"location":"associate/#events-associator-from-library","title":"Events Associator from Library","text":""},{"location":"associate/#classes","title":"Classes","text":"<p><code>RealCore</code></p> <pre><code>class RealCore:\n    def __init__(self, metadata_file: str, real_config: Union[str, RealConfig], picking_directory: str, working_directory: str,\n                 output_directory: str):\n\n        \"\"\"\n        ----------\n        Parameters\n        ----------\n        metadata_file str: Path to the inventory information of stations coordinates and instrument description\n        real_config: Either the path to a real_config.ini or a RealConfig object.\n        picking_directory str: Root path to the folder wher picks P and S wave arrival time picks are storage\n        working_directory str: Root path to the folder that the associator uses to save intermediate files sucha as travel-times.\n        \"\"\"\n</code></pre>"},{"location":"associate/#methods","title":"Methods","text":"<p><code>run_real</code></p> <pre><code># instance method\ndef run_real(self):\n    # starts the events associator\n</code></pre>"},{"location":"associate/#example-using-library","title":"example using library","text":"<pre><code>from surfquakecore.real.real_core import RealCore\n\n# Inventory Information\ninventory_path = \"/meta/inv_all.xml\"\n\n# picking Output of PhaseNet\npicks_path = '/test_surfquake_core/picks'\n\n# Set working_directory and output\nworking_directory = '/test_surfquake_core/test_real/working_directory'\noutput_directory = '/test_surfquake_core/test_real/output_directory'\n\n# Set path to REAL configuration\nconfig_path = surfquake_test/config_files/real_config.ini\n# Run association\nrc = RealCore(inventory_path, config_path, picks_path, working_directory, output_directory)\nrc.run_real()\nprint(\"End of Events AssociationProcess, please see for results: \", output_directory)\n</code></pre>"},{"location":"db/","title":"DataBase","text":""},{"location":"db/#populate","title":"Populate","text":"<ul> <li>Pick in File/Read Hyp Folder to incorporate all information contained inside hyp folders. Hyp folders are the file output from location.</li> <li>Pick in File/Magnitudes to populate your database with the information from the output file obtained in source toolbox.</li> <li>Pick in File/MTI to populate your database with the information from the output file obtained in MTI toolbox.</li> </ul>"},{"location":"db/#queryng","title":"Queryng","text":"<p>Choose the options on the left widget to filter the hypocenter inside your DataBase. The eartquakes shown in the table can be used in the MTI GUI when runs the inversion.</p>"},{"location":"db/#phase-information","title":"Phase Information","text":"<p>Click with right button to get the phases information corresponding to the selected event</p> <p></p>"},{"location":"db/#visual-options","title":"Visual Options","text":"<p>Double Clik near an epicenter in the map and it will be hilighted the corresponding row in the table.</p> <p>Double Click in a epicenter in the table and (if here is MTI information) it will be plot the beachball in the map</p> <p>Click with right button in a table row and select highlight event to visualize the exact event in the map.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#processor-and-os","title":"Processor and OS","text":"<p>Linux OS and Mac computers with Intel processors can now run surQuake thanks to testing and programming. </p> <p>Additionally, Rosetta allows Mac machines with Apple chips to run applications meant for Mac systems with Intel processors. If this is your case, please install Rosseta before proceed with surfQuake intallation</p> <p>The user can select whether to install only the surfQuake core or the GUI (which also includes the core). </p> <ul> <li> <p>Automatic installation: This is only available in surfQuake GUI and requires a previous installation of Anaconda.</p> </li> <li> <p>Manual Installation: In both circumstances (GUI &amp; Core), SurfQuake must be manually installed from the pip repository after creating an environment (anaconda env or pip env).</p> </li> </ul>"},{"location":"install/#installing-the-gui","title":"Installing the GUI","text":""},{"location":"install/#automatic-installation","title":"Automatic Installation:","text":"<p>This process will create atomatically an anaconda environment and then will install surfquake.</p> <p>Open a terminal and type:</p> <pre><code>&gt;&gt; (base) git clone https://github.com/rcabdia/SurfQuake.git\n&gt;&gt; (base) cd SurfQuake/install\n&gt;&gt; (base) chmod u+x surfquake_installer.sh\n&gt;&gt; (base) ./surfquake_installer.sh\n</code></pre> <p>After this process, if everything is ok and the alias has been correctly included in your path system, just type in your terminal</p> <p><pre><code>&gt;&gt; surfquake\n</code></pre> if you have problems because surfquake is not properly recognized by your system path, go to the root path where you have saved surfquake,</p> <pre><code>&gt;&gt; (base) cd SurfQuake\n&gt;&gt; (base) conda activate surfquake\n&gt;&gt; (surfquake) python start_surfquake.py\n</code></pre> <p>Remenber that installing surfquake GUI also includes the core Library and the Command Line interface. That's means that now you have access to the commands <pre><code>&gt;&gt; (surfquake) surfquake -h\n</code></pre></p> <p>and you can make python scripts calling classes and methods from surfquake core.</p>"},{"location":"install/#manual-installation","title":"Manual Installation:","text":""},{"location":"install/#create-an-environment","title":"Create an environment","text":""},{"location":"install/#anaconda","title":"Anaconda","text":"<pre><code>&gt;&gt; (base) conda create -n surfquake python=3.9\n&gt;&gt; (base) conda activate surfquake\n</code></pre>"},{"location":"install/#pip","title":"pip","text":"<p>Warning, if you are using anaconda, normally is automatically activated the base environment in your terminal. So first of all deactivate it!</p> <pre><code>&gt;&gt; (base) conda deactivate\n</code></pre> <pre><code>&gt;&gt; pip install virtualenv\n&gt;&gt; python&lt;version&gt; -m venv surfquake\n&gt;&gt; source surfquake/bin/activate # activate your environment\n</code></pre>"},{"location":"install/#execute-the-installation","title":"Execute the Installation","text":"<p>Now, you can proceed with the installation of the full surfQuake program:</p> <pre><code>&gt;&gt; (surfquake) cd SurfQuake\n&gt;&gt; (surfquake) pip install -r requirements.txt\n</code></pre> <p>to start the program</p> <pre><code>&gt;&gt; (surfquake) cd SurfQuake\n&gt;&gt; (surfquake) python start_surfquake.py\n</code></pre>"},{"location":"install/#installing-the-core","title":"Installing the core","text":""},{"location":"install/#create-an-environment_1","title":"Create an environment","text":""},{"location":"install/#anaconda-env","title":"Anaconda env","text":"<pre><code>&gt;&gt; conda create -n surfquake python=3.9 # surfQuake for 3.9 &lt;= Python &lt;= 3.11\n&gt;&gt; conda activate surfquake\n</code></pre>"},{"location":"install/#pip-env","title":"pip env","text":"<p>Warning, if you are using anaconda, normally is automatically activated the base environment in your terminal. So first of all deactivate it! </p> <pre><code>&gt;&gt; (base) conda deactivate\n</code></pre> <p>To prevent dependencies from becoming incompatible, please make sure that the version of Python you have installed on your system is greater than 3.9 and less than 3.12. Simply follow these steps to view your Python version:</p> <pre><code>&gt;&gt; python\nPython 3.11.4 (main, Jul  5 2023, 09:00:44) [Clang 14.0.6 ] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information\n</code></pre> <pre><code>&gt;&gt; pip install virtualenv # install in your python the virtualenv package (just in case)\n&gt;&gt; python3 -m venv ./surfquake # python&lt;version&gt; -m &lt;virtual-environment-name&gt; &lt;venv_location&gt; \n&gt;&gt; source surfquake/bin/activate #s ource &lt;venv_location&gt;\n</code></pre>"},{"location":"install/#install-the-core-package","title":"Install the core package","text":"<p>You can install surfQuake core after creating your virtual environment (using either Anaconda env or Pip env). After activate your environment,</p> <pre><code>&gt;&gt; (surfquake) pip install surfquake\n</code></pre>"},{"location":"locate/","title":"Event Location","text":"<p>The Event Location toolbox uses Non Lin Loc, Lomax et ., 2009 to locate seismic events.</p>"},{"location":"locate/#previous-knowledge","title":"Previous knowledge","text":"<p>First we include here, previous knowlege about files you need to set to run event locations.</p>"},{"location":"locate/#the-picking-file","title":"The Picking File","text":"<p>The picking file NonLinLoc Phase file format nll_input.txt is automatically generated when the associator. However, you can make it by your own. Here, it's attached how is the file describing one event. For more events just you need yo write the picking info separated by a blank row. The location algorythm will locate all events with picking information inside the file</p> <pre><code>Station_name    Instrument  Component   P_phase_onset   P_phase_descriptor  First_Motion    Date    Hourmin Seconds GAU Err Coda_duration   Amplitude   Period\nARBS    ?   ?   ?   P   ?   20220126    0200    14.700  GAU 2.50E-03    -1.00E+00   85600000.0  -1.00E+00\nARBS    ?   ?   ?   S   ?   20220126    0200    16.320  GAU 7.50E-03    -1.00E+00   85600000.0  -1.00E+00\nCORG    ?   ?   ?   P   ?   20220126    0200    18.210  GAU 2.50E-03    -1.00E+00   17000000.0  -1.00E+00\nCORG    ?   ?   ?   S   ?   20220126    0200    23.020  GAU 7.50E-03    -1.00E+00   17000000.0  -1.00E+00\nPAND    ?   ?   ?   P   ?   20220126    0200    14.200  GAU 2.50E-03    -1.00E+00   132000000000.0  -1.00E+00\nPAND    ?   ?   ?   S   ?   20220126    0200    15.550  GAU 2.50E-03    -1.00E+00   132000000000.0  -1.00E+00\nCSOR    ?   ?   ?   P   ?   20220126    0200    17.510  GAU 2.50E-03    -1.00E+00   45200000.0  -1.00E+00\nCSOR    ?   ?   ?   S   ?   20220126    0200    21.330  GAU 5.00E-03    -1.00E+00   99900000.0  -1.00E+00\nCEST    ?   ?   ?   P   ?   20220126    0200    15.570  GAU 2.50E-03    -1.00E+00   74500000.0  -1.00E+00\nCEST    ?   ?   ?   S   ?   20220126    0200    17.660  GAU 2.50E-03    -1.00E+00   90000000.0  -1.00E+00\nSALF    ?   ?   ?   P   ?   20220126    0200    18.080  GAU 5.00E-03    -1.00E+00   7240000000.0    -1.00E+00\nSALF    ?   ?   ?   S   ?   20220126    0200    21.930  GAU 7.50E-03    -1.00E+00   24900000000.0   -1.00E+00\nGENF    ?   ?   ?   P   ?   20220126    0200    18.470  GAU 2.50E-03    -1.00E+00   20100000.0  -1.00E+00\nGENF    ?   ?   ?   S   ?   20220126    0200    22.730  GAU 5.00E-03    -1.00E+00   43900000.0  -1.00E+00\nCARF    ?   ?   ?   P   ?   20220126    0200    22.230  GAU 2.50E-03    -1.00E+00   1750000000.0    -1.00E+00\nCARF    ?   ?   ?   S   ?   20220126    0200    29.370  GAU 7.50E-03    -1.00E+00   2870000000.0    -1.00E+00\n</code></pre>"},{"location":"locate/#earth-model-settings","title":"Earth Model Settings","text":"<p>We have created a repository with an example of 1D and 3D model that describes the SW Iberian Peninsula using a Grandin et ., 2007 to rapidly visualize the model Cabieces et al 2020 </p> <p>The model 1D: In the root path to your model, in this case at /Volumes/LaCie/surfquake_test/test_nll_final/model1D create two files called modelP and modelS. The files will be exactly the same but called differnlt. The are easily described as follows:</p> <p>LAYER depth VpTop VpGrad VsTop VsGrad rhoTop rhoGrad</p> <ul> <li>depth (float) depth to top of layer (use negative values for layers above z=0)</li> <li>VpTop VsTop rhoTop P velocity, and S velocity in km/s and density in kg/m**3 at the top of the layer.</li> <li>VpGrad VsGrad rhoGrad Linear P velocity and S velocity gradients in km/s/km and density gradient in kg/m**3/km increasing directly downwards from the top of the layer.</li> </ul> <p>Summarizing for the hungry users. Copy and paste this lines into your files called modelP and modelS and place it into the root folder previouly set as PATH_TO_1D_MODEL in the config file or for GUI users in the root folder you select as earth model.</p> <pre><code>LAYER   0.0  6.1 0.0    3.49  0.0  2.7 0.0\nLAYER  11.0  6.4 0.0    3.66  0.0  2.7 0.0\nLAYER  24.0  6.9 0.0    3.94  0.0  2.7 0.0\nLAYER  31.0  8.0 0.0    4.57  0.0  2.7 0.0\nLAYER    45.63   8.0412  0.000118   4.4737  0.000353\nLAYER    56.25   8.0425  0.000118   4.4775  0.000353\nLAYER    66.88   8.0437  0.000118   4.4813  0.000353\nLAYER    77.50   8.0450  0.000118   4.4850  0.000353\nLAYER    88.13   8.0463  0.000118   4.4887  0.000353\nLAYER    98.75   8.0475  0.000118   4.4925  0.000353\nLAYER   109.38   8.0488  0.000120   4.4962  0.000353\nLAYER   120.00   8.0500  0.002775   4.5000  0.000200\n</code></pre> <p>The model 3D:</p> <p>Every depth layer must be placed in files called, for example</p> <pre>\n    <code>\nFor the P wave --&gt; layer.P.mod5.mod\nFor the S wave --&gt; layer.S.mod5.mod\n    </code>\n</pre> <p>Which means that inside this file there is the grid with the value of the Vp or Vs, for the layer at depth 5km.</p> <p>The layer must be a matrix with the values in the rows from top to bottom S -&gt; N, and from left to right E -&gt; W. That's mean following the next example that the file corresponding to a depth layer 5km \"layer.P.mod5.mod\" could be like this:</p> <pre>\n    <code>\n4.5759 4.5735 ...... 4.5707 4.5677\n4.5760 4.5755 ...... 4.5766 4.5670\n...... ...... ...... ...... ......\n4.6800 4.6500 ...... 4.6730 4.5678\n    </code>\n</pre> <p>This matrix means that, for example corresponds to geographic points long,lat (separated in cells of, dx dy of 0.5 x 0.5 degrees.</p> <pre>\n    <code>\n(-10.0,34.0) (-9.5,34.0) ...... (-9.0,34.0) (-8.5,34.0)\n(-10.0,34.5) (-9.5,34.5) ...... (-9.0,34.5) (-8.5,34.5)\n....... ..... ..... .... ...... .... ...... ...........\n(-10.0,40.0) (-9.5,40.0) ...... (-9.0,40.0) (-8.5,40.0)\n    </code>\n</pre> <p>Warning grid cells must be [dx = dy = dz] for a correct interpretation.</p>"},{"location":"locate/#event-location-gui","title":"Event Location GUI","text":"<p>This is a screenshot of the Event Location GUI.</p> <p></p> <ul> <li>Location Parameters: Just set the paths to the workflow.<ul> <li>Work / Ouput Directory: Set the root path where the necessary working directories structure will be created. In this structure will be build the velocity grid, travel-times tables and the location output.</li> <li>Model Folder Path: Set the path to your 1D or 3D model folder. Go to CLI section to see further details of how to configurate your Earth Model.</li> <li>Pick File: Set the path to the pick file. Picking file nll_input.txt output from associator toolbox contains all phase info o run the event locations.</li> </ul> </li> <li>Grid Configuration:<ul> <li>Grid Reference: SW corner of your geographic framework</li> <li>Grid Dimension in the x, y and z number of points and dx, dy dx the size in each dimension. For example the size in the X/East axis, X = dx*(x-1)</li> <li>Geographic Transformation: Simple or Global. Warning if Global is selected go directly to press Run Location </li> <li>Grid Type: Slowness (Default)</li> <li>Wave: P &amp; S or P. This will guide the software to know wich can of velocity grid create.</li> <li>Model: 1D or 3D</li> </ul> </li> <li>Travel Times:<ul> <li>Select type of grid GRID1D or GRID3D and the corresponding wave P &amp; S or S</li> <li>Distance Limit: The maximum distance from the center of the grid  - station,  to compute the travel-time</li> </ul> </li> <li>Location parameters:<ul> <li>search: algorythm to be used in the search of the location solution</li> <li>Method</li> </ul> </li> </ul>"},{"location":"locate/#grid-definition","title":"Grid Definition","text":"<p>One the most important parts is the geographic framework settings. In the figure is displayed an example of stations distrubition (orange triangles and blue squares) inside the region of study(shaded square) with probable epicenters (red circle). Simply, the user must set the grid coordinates origin, the resolution dx, dy and dz, plus the number of points in the grid X, Y, Z. Remind that the configuration follow the left hand rule so positive W-&gt;E, S-&gt;N, Top -&gt; Bottom in depth.</p>"},{"location":"locate/#config-file","title":"Config File","text":"<p>In the next section CLI and Library the user can configurate the event location tool from a config file type file.ini, an example of the typical configuration for locate local/regional events using a 1D-model as follows:</p> <pre><code>[GRID_CONFIGURATION]\nLATITUDE = 41.0000\nLONGITUDE = 0.0000\nDEPTH_KM = -3.0\nX = 400\nY = 400\nZ = 50\nDX = 1\nDY = 1\nDZ = 1\nGEO_TRANSFORMATION = SIMPLE\nGRID_TYPE = SLOW_LEN\nPATH_TO_PICKS = /Volumes/LaCie/surfquake_test/test_real_final/nll_input.txt\nPATH_TO_1D_MODEL = /Volumes/LaCie/surfquake_test/test_nll_final/model1D\nPATH_TO_3D_MODEL = NONE\nMODEL = 1D\nP_WAVE_TYPE = TRUE\nS_WAVE_TYPE = TRUE\n#\n[TRAVEL_TIMES_CONFIGURATION]\nDISTANCE_LIMIT = 500\nGRID = 1D\n\n#\n[LOCATION_PARAMETERS]\nSEARCH = OCT-TREE\nMETHOD = GAU_ANALYTIC\n</code></pre> <p>In the section Location_Parameters SEARCH is just available OCT that corresponds to the Octree algorythm.  In Method you can change to:</p> <ul> <li>GAU_ANALYTIC the inversion approach of Tarantola and Valette (1982) with L2-RMS likelihood function. </li> <li>EDT Equal Differential Time likelihood function cast into the inversion approach of Tarantola and Valette (1982) <ul> <li>EDT_OT_WT Weights EDT-sum probabilities by the variance of origin-time estimates over all pairs of readings. This reduces the probability (PDF values) at points with inconsistent OT estimates, and leads to more compact location PDF's. </li> <li>EDT_OT_WT_ML version of EDT_OT_WT with EDT origin-time weighting applied using a grid-search, maximum-likelihood estimate of the origin time. Less efficient than EDT_OT_WT which uses simple statistical estimate of the origin time.</li> </ul> </li> </ul>"},{"location":"locate/#event-location-from-cli","title":"Event Location from CLI","text":""},{"location":"locate/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake locate seismic event [-h] -i INVENTORY_FILE_PATH -c CONFIG_FILE_PATH -o OUT_DIR_PATH [-g] [-s]\n</code></pre>"},{"location":"locate/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake locate -h\n</code></pre>"},{"location":"locate/#run-event-location-from-cli","title":"Run Event Location from CLI","text":"<pre><code>&gt;&gt; surfquake locate -i /surfquake_test/metadata/inv_all.xml -c /surfquake_test/config_files/nll_config.ini -o /surfquake_test/test_nll_final -g -s\n</code></pre>"},{"location":"locate/#event-location-from-library","title":"Event Location from Library","text":""},{"location":"locate/#classes","title":"Classes","text":"<p><code>NllManager</code></p> <pre><code>class NllManager:\n\n    def __init__(self, nll_config: Union[str, NLLConfig], metadata_path, working_directory):\n        \"\"\"\n        Manage NonLinLoc program to locate seismic events.\n        :param nll_config: Path to nll_config.ini file or to NLLConfig object.\n        :param metadata_path: Path to metadata file.\n        :param working_dirctory: Root path to folder to establish the working and output structure.\n        \"\"\"\n        self.__get_nll_config(nll_config)\n        self.__location_output = working_directory\n        self.__create_dirs()\n        self.__dataless_dir = metadata_path\n        self.__metadata_manager = None\n</code></pre>"},{"location":"locate/#methods","title":"Methods","text":"<p><code>vel_to_grid</code> <pre><code># instance method\ndef vel_to_grid(self):\n    \"\"\"\n    # Method to generate the velocity grid #\n    :return: Extracts the velocity grid as layer*.buf and layer*.hdr inside working_dir/model\n    template file temp.txt in working_dir/temp.txt\n    \"\"\"\n</code></pre></p> <p><code>grid_to_time</code> <pre><code># instance method\ndef grid_to_time(self):\n    \"\"\"\n    # Method to generate the travel-time tables file #\n    :return: Extracts the travel-times per wave type as\n    [layer.P.STA.angle.buf, layer.P.STA.time.buf, layer.P.STA.time.hdr]\n    inside ./working_dir/time\n    template file at ./work_dir/temp/G2T_temp.txt\n    \"\"\"\n</code></pre></p> <p><code>run_nlloc</code> <pre><code># instance method\ndef run_nlloc(self):\n    \"\"\"\n    # Method to run the event locations from the picking file and config_file.ini #\n    :return: locations files *hyp inside ./working_dir/loc\n    template file at ./work_dir/temp/run_temp.txt\n    \"\"\"\n</code></pre></p>"},{"location":"locate/#example-using-library","title":"Example using library","text":"<pre><code>import os\nfrom surfquakecore.earthquake_location.run_nll import Nllcatalog, NllManager\n\nif __name__ == \"__main__\":\n    cwd = os.path.dirname(__file__)\n    # Basic input: working_directory, inventory file path and config_file input\n    working_directory = os.path.join(cwd, \"earthquake_locate\")\n    inventory_path = os.path.join(working_directory, \"inventories\", \"inv_surfquakecore.xml\")\n    path_to_configfiles = os.path.join(working_directory, \"config/nll_config.ini\")\n    nll_manager = NllManager(path_to_configfiles, inventory_path, working_directory)\n    nll_manager.vel_to_grid()\n    nll_manager.grid_to_time()\n    for iter in range(0, 10):\n        print('Locating ', iter)\n        nll_manager.run_nlloc()\n    nll_catalog = Nllcatalog(working_directory)\n    nll_catalog.run_catalog(working_directory)\n</code></pre>"},{"location":"mass_processing/","title":"Mass Data Processing with SurfQuake","text":"<p>\u26a0\ufe0f Note: This feature is under active development. The expected stable release is SurfQuake 0.0.9 (July 2025).</p> <p>Welcome to the Mass Processing Module of SurfQuake \u2014 a powerful and scalable command-line tool for applying signal processing pipelines to large collections of seismic waveform data.</p> <p>Whether you're analyzing earthquake catalogs or preparing data for machine learning models, this module allows you to define, control, and automate your signal processing workflow with precision.</p> <p>\ud83d\udcd8 Learn more in our Signal Processing Tutorial</p>"},{"location":"mass_processing/#macro-structure-overview","title":"\ud83e\udded Macro Structure Overview","text":"<p>The macro configuration (provided via a YAML file) defines your signal processing pipeline in a structured, step-by-step format. Each <code>process</code> entry specifies a method, its parameters, and the order in which it will be applied to each trace. You can process either full daily waveform files or extract and process specific segments based on an event file. Additionally, an interactive plotting tool is available to help you visually inspect and validate the processing steps.</p>"},{"location":"mass_processing/#detrending","title":"\ud83d\udd27 Detrending","text":"<p>Remove unwanted trends from the raw signal:</p> <ul> <li><code>linear</code>: Remove a best-fit line</li> <li><code>demean</code>: Subtract the mean</li> <li><code>polynomial</code>: Fit and subtract a polynomial (e.g., degree 3)</li> <li><code>spline</code>: Subtract a smooth spline fit</li> </ul>"},{"location":"mass_processing/#tapering","title":"\ud83e\ude9f Tapering","text":"<p>Apply a window to reduce spectral leakage near signal edges.</p> <ul> <li>Parameter: <code>max_percentage</code> (e.g., 0.05 for 5%)</li> <li>Supported Windows:   <code>cosine</code>, <code>hann</code>, <code>hamming</code>, <code>blackman</code>, <code>kaiser</code>, <code>flattop</code>, <code>slepian</code>, and many more...</li> </ul>"},{"location":"mass_processing/#normalize","title":"\u2696\ufe0f Normalize","text":"<p>Rescale amplitude:</p> <ul> <li><code>0</code>: Normalize by maximum</li> <li>Custom value: Divide signal by provided constant</li> </ul>"},{"location":"mass_processing/#filtering","title":"\ud83c\udf9a Filtering","text":"<p>Apply filters to isolate specific frequency content.</p> <ul> <li>Parameters: <code>freqmin</code>, <code>freqmax</code>, <code>zerophase</code>, <code>corners</code> (poles)</li> <li>Filter Types:</li> <li><code>bandpass</code>, <code>lowpass</code>, <code>highpass</code>, <code>bandstop</code></li> <li>Parametric options: <code>cheby1</code>, <code>cheby2</code>, <code>elliptic</code>, <code>bessel</code></li> </ul> <p>\u2139\ufe0f Ensure <code>freqmin &lt; freqmax</code> for band filters.</p>"},{"location":"mass_processing/#denoising","title":"\ud83e\uddfc Denoising","text":""},{"location":"mass_processing/#wiener-filter","title":"Wiener Filter","text":"<ul> <li>Parameters: <code>time_window</code> (seconds), <code>noise_power</code> </li> <li>Tip: If <code>noise_power=0</code>, it\u2019s estimated from local variance.</li> </ul>"},{"location":"mass_processing/#wavelet-denoise","title":"Wavelet Denoise","text":"<ul> <li>Parameters: <code>wavelet_family</code> (e.g., <code>sym8</code>), <code>threshold</code> (e.g., 0.05)</li> </ul>"},{"location":"mass_processing/#resampling","title":"\ud83d\udd01 Resampling","text":"<p>Adjust the sampling rate (e.g., for standardization):</p> <ul> <li>Parameters: <code>new_sampling_rate</code>, <code>pre_filter</code> (recommended: <code>True</code>)</li> </ul>"},{"location":"mass_processing/#fill-gaps","title":"\ud83e\udde9 Fill Gaps","text":"<ul> <li>Methods: <code>interpolate</code>, <code>latest</code> (repeat last value)</li> </ul>"},{"location":"mass_processing/#differentiate","title":"\u2202 Differentiate","text":"<p>Estimate the signal\u2019s derivative:</p> <ul> <li>Methods: <code>gradient</code></li> </ul>"},{"location":"mass_processing/#integrate","title":"\u222b Integrate","text":"<p>Reconstruct displacement or velocity:</p> <ul> <li>Methods: <code>cumtrapz</code>, <code>spline</code></li> </ul>"},{"location":"mass_processing/#time-shifting","title":"\ud83d\udd52 Time Shifting","text":"<p>Shift traces forward or backward in time.</p> <ul> <li>Parameter: List of time shifts in seconds</li> </ul>"},{"location":"mass_processing/#remove-instrument-response","title":"\ud83c\udf9b Remove Instrument Response","text":"<p>Convert raw counts to physical units (e.g., velocity or displacement):</p> <ul> <li>Parameters: <code>pre_filt</code> (list), <code>water_level</code>, <code>units</code>, <code>inventory</code></li> </ul>"},{"location":"mass_processing/#add-noise","title":"\ud83d\udce2 Add Noise","text":""},{"location":"mass_processing/#white-noise","title":"White Noise:","text":"<ul> <li>Parameter: <code>SNR_dB</code> relative to original trace</li> </ul>"},{"location":"mass_processing/#colored-noise-optional-not-in-base-config","title":"Colored Noise (optional, not in base config):","text":"<ul> <li>Use <code>exponent</code> for control: 0 (white), 1 (pink), 2 (brown), -1 (blue), etc.</li> </ul>"},{"location":"mass_processing/#spectral-whitening","title":"\ud83d\udfe6 Spectral Whitening","text":"<p>Flattens signal spectrum while preserving phase:</p> <ul> <li>Parameters: <code>freq_width</code> (Hz), <code>taper_edge</code> (True/False)</li> </ul>"},{"location":"mass_processing/#time-normalization","title":"\ud83d\udcc8 Time Normalization","text":"<p>Standardize temporal energy distribution:</p> <ul> <li>Methods: <code>time-normalization</code>, <code>1bit</code>, <code>clipping</code></li> <li>Parameters: <code>norm_win</code>, <code>iterations</code></li> </ul>"},{"location":"mass_processing/#smoothing","title":"\ud83c\udf2b Smoothing","text":"<p>Reduce high-frequency noise or jitter:</p> <ul> <li>Parameters: <code>time_window</code>, <code>fwhm</code></li> <li>Methods: <code>mean</code>, <code>gaussian</code>, <code>tkeo</code></li> </ul>"},{"location":"mass_processing/#spike-removal","title":"\u2702\ufe0f Spike Removal","text":"<p>Removes isolated outliers using hampel algorithm:</p> <ul> <li>Parameters: <code>window_size</code>, <code>threshold</code> (in standard deviations)</li> </ul>"},{"location":"mass_processing/#running-the-process","title":"\u2699\ufe0f Running the Process","text":"<p>This tool runs via the terminal:</p> <pre><code>surfquake processing -h\n</code></pre> <pre><code>surfquake processing -p [project_file] -o [output_folder] -i [metadata_file] -c [config_file] \\\n-e [event_file] -n [network] -s [station] -ch [channel] -st [start_time] -et [end_time] \\\n-cs [cut_start] -ce [cut_end] -t [cut_time] -r -l\n</code></pre>"},{"location":"mass_processing/#event-file-format","title":"\ud83d\udcc1 Event File Format","text":"<pre><code>date;hour;latitude;longitude;depth;magnitude\n2022-02-02;23:35:29.7;42.5089;1.4293;20.7;1.71\n2022-02-03;12:01:21.6;42.3047;2.2741;0.0;1.65\n</code></pre>"},{"location":"mass_processing/#example-config-file-yaml","title":"\ud83e\uddfe Example Config File (YAML)","text":"<pre><code>Analysis:\n  process_1:\n    name: 'taper'\n    method: 'hann'\n    max_percentage: 0.05\n  process_2:\n    name: 'rmean'\n    method: 'simple'\n  process_3:\n    name: 'normalize'\n    norm:\n  process_4:\n    name: 'differentiate'\n    diff: true\n  process_5:\n    name: 'integrate'\n    method: 'spline'\n  process_6:\n    name: 'filter'\n    method: 'bandpass'\n    freqmin: 4.0\n    freqmax: 8.0\n  process_7:\n    name: 'wiener_filter'\n    time_window: 0\n    noise_power: 0\n  process_8:\n    name: 'remove_response'\n    inventory: 'metadata.xml'\n    water_level: 60\n    units: 'Wood Anderson'\n    pre_filt: [1, 2, 3, 4]\n  process_9:\n    name: 'add_white_noise'\n    SNR_dB: 10\n  process_10:\n    name: 'whitening'\n    freq_width: 0.04\n    taper_edge: True\n  process_11:\n    name: 'remove_spikes'\n    window_size: 10\n    n: 4\n  process_12:\n    name: 'time_normalization'\n    method: '1bit'\n    norm_win: 10\n  process_13:\n    name: 'wavelet_denoise'\n    dwt: 'db2'\n    threshold: 0.5\n  process_14:\n    name: 'resample'\n    pre_filter: True\n    sampling_rate: 100\n  process_15:\n    name: 'fill_gaps'\n    method: 'interpolate'\n  process_16:\n    name: 'smoothing'\n    method: 'gaussian'\n    time_window: 5\n    FWHM: 0.05\n</code></pre>"},{"location":"mti/","title":"Automatic Moment Tensor Inversion","text":"<p>The focal mechanism of the pre-located events is automatically estimated using a optimized version of Bayesian Isola (Vack\u00e2r et al., 2017). The MTI is run over a set of events. The events can be selected quering the database through the GUI, giving a folder path with mti_config.ini files or even making instances of the class for each event and running the inversion from the core library. Moreover, for Core library and CLI users, it can be automatically generated the MTI config files from a catalog object, see Build MTI config files in Utilities section.</p>"},{"location":"mti/#mti-gui","title":"MTI GUI","text":"<ul> <li> <p>Working Framework:</p> <ul> <li> <p>Working Dirctory (no required): Folder where Green functions a temporal files will be saved.</p> </li> <li> <p>Output Directory: Rooth path to the folder where output from event inversions will be saved.</p> </li> <li> <p>Earth Model File: File path to he earth model. An example as follows:</p> </li> </ul> </li> </ul> <pre><code>Crustal model                  IBERIA\nnumber of layers \n   7\nParameters of the layers\ndepth of layer top(km)   Vp(km/s)    Vs(km/s)    Rho(g/cm**3)    Qp     Qs\n      0.0                 6.10       3.490        2.920         300    300\n     11.0                 6.40       3.660        2.980         300    300\n     24.0                 6.90       3.940        3.080         300    300\n     31.0                 8.00       4.570        3.300         300    300\n     45.6                 8.04       4.474        3.308         300    300\n     56.2                 8.04       4.478        3.309         300    300\n     66.9                 8.04       4.481        3.309         300    300\n*************************************************************************\n</code></pre> <ul> <li> <p>Grid search: Defines a geographic grid centered in the estimated hypocenter where surfquake will proceed with the search of the best MTI.</p> <ul> <li> <p>Horizontal Location Uncertainity: Maximum horizontal range of the search.</p> </li> <li> <p>Horizontal search step: Horizontal resolution of the grid search.</p> </li> <li> <p>Depth Uncertainty: Maximum vertical range of the search.</p> </li> <li> <p>Depth Search step: Vertical resolution of the grid search.</p> </li> <li> <p>Time Uncertainity: Time shift around the event origin time.</p> </li> </ul> </li> <li> <p>Inversion Parameters: Defines parameters realtd to the source and the inversion process.</p> </li> <li>Traces Selection Criteria: Defin the criteria to include or not seismograms to your inversion</li> </ul> <p>Now, that you have parametrized your inversion follow the steps:</p> <ol> <li>Inside Project: Load your project and load your Metadata.</li> <li>Inside The DataBase dedicated GUI.<ul> <li>Fill your DataBase loading that files from the folder where you have the location files.</li> <li>Not required but very recommended populate your DataBase with the information from the output of Source. This will give the database information about Magnitudes and will facilitate the MTI.</li> </ul> </li> <li>Make a Query to filter your Database</li> <li>Without closing DataBase GUI, press Run Inversion.</li> <li>Track the evolution of your inversions in the output dirctory, finally press print Results.</li> <li>Populate your dataBase with the information from the output of MTIs.</li> </ol>"},{"location":"mti/#mti-config-file","title":"MTI Config File","text":"<p>In the following sections CLI and Core library the user can use mti_config.ini files to define each event where surfquake will carry out the MTIs. You can storage a single event per file. So, place all files inside the same folder. Please find here an example of mti_config.ini file (the name of the .ini file doen't matter just extension .ini). Additionally, be in mind that users can create automatically mti config files. Go to section  Build MTI config files using the Library inside Utils. You can use the following mti config file information to make your own template.</p> <pre><code>[ORIGIN]\nORIGIN_DATE = 21/08/2018 00:28:57.000\nLATITUDE = 42.7059\nLONGITUDE= -7.6974\nDEPTH_KM = 11.0\nMAGNITUDE = 3.5\n\n[STATIONS_AND_CHANNELS]\n# add the station name follow by channels split by a comma , and use .+ for all channels\nELOB = HHZ, HHN, HHE \nEPON = .+\nEMAZ = .+\n\n[MTI_PARAMETERS]\nEARTH_MODEL_FILE = /earth_models/Iberia.dat\nLOCATION_UNC = 3000\nTIME_UNC = 0.5\nDEVIATORIC = True\nDEPTH_UNC = 3000\nCOVARIANCE = True\nRUPTURE_VELOCITY = 2500\nSOURCE_TYPE = Triangle\nMIN_DIST = 50\nMAX_DIST = 500\nMAX_NUMBER_STATIONS = 15\nSOURCE_DURATION = 2\n\n[SIGNAL_PROCESSING]\nREMOVE_RESPONSE = True\nMAX_FREQ = 0.08\nMIN_FREQ = 0.04\nRMS_THRESH = 5.0\n</code></pre> <p>Units: LOCATION_UNC [m], TIME_UNC [s], DEPTH_UNC[m], RUPTURE_VELOCITY [m/s], MIN_DIST [km], MAX_DIST [km], SOURCE_DURATION [s],  RMS_THRESH [avarage ratio signal / noise]. If MIN_DIST and MAX_DIST automatically will be used MIN_DIST = 2 * rupture_length, MAX_DIST = 2 ** (mti_config.magnitude) * 2</p>"},{"location":"mti/#mti-from-cli","title":"MTI from CLI","text":""},{"location":"mti/#usage","title":"Usage","text":"<pre><code>surfquake mti -i [inventory_file_path] -p [path_to_project] -c [path to mti_config_file.ini] \n        -o [output_path]  -s [if save plots]\n</code></pre>"},{"location":"mti/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake mti -h\n</code></pre>"},{"location":"mti/#run-mti-from-cli","title":"Run MTI from CLI","text":"<pre><code>&gt;&gt; surfquake mti -i /mti_run_inversion_resources/inv_surfquakecore.xml -p /project/surfquake_project_mti.pkl -o /test_mti -c /surfquake_test/mti_configs -s\n</code></pre>"},{"location":"mti/#mti-from-library","title":"MTI from Library","text":""},{"location":"mti/#classes","title":"Classes","text":"<p><code>BayesianIsolaCore</code> <pre><code>class BayesianIsolaCore:\n    def __init__(self, project: SurfProject, inventory_file: str,\n                 output_directory: str, save_plots=False):\n        \"\"\"\n\n        :param project: SurfProject object\n        :param inventory_file: File to the metadata file\n        :param output_directory: Root path to the output directory where inversion results will be saved\n        :param save_plots: if figures summarizing the results for each inversion are desired\n        \"\"\"\n</code></pre></p>"},{"location":"mti/#methods","title":"Methods","text":"<p><code>run_inversion</code> <pre><code># instance method\ndef run_inversion(self, mti_config: Union[str, MomentTensorInversionConfig], **kwargs):\n\n    \"\"\"\n    This method should be to loop over config files and run the inversion.\n    Previously it is needed to load the project and metadata.\n\n    Args:\n        mti_config: Either a directory of .ini files, a .ini file or an instance of MomentTensorInversionConfig\n        **kwargs:\n\n    Returns:\n\n    \"\"\"\n</code></pre></p> <p><code>read_isola_result</code> <pre><code>def read_isola_result(file: str) -&gt; MomentTensorResult:\n    \"\"\"\n    Reads the ISOLA-ObsPy output inversion.json file.\n\n    :param file: The location of inversion.json from isola.\n    :return: Dict\n    \"\"\"\n</code></pre></p>"},{"location":"mti/#example-using-library","title":"Example using library","text":"<pre><code>import os\nfrom surfquakecore.moment_tensor.mti_parse import read_isola_log, read_isola_result\nfrom surfquakecore.moment_tensor.sq_isola_tools.sq_bayesian_isola import BayesianIsolaCore\nfrom surfquakecore.project.surf_project import SurfProject\nfrom surfquakecore.moment_tensor.mti_parse import WriteMTI\n\ndef list_files_with_iversion_json(root_folder):\n    iversion_json_files = []\n\n    for foldername, subfolders, filenames in os.walk(root_folder):\n        for filename in filenames:\n            if filename == \"iversion.json\":\n                iversion_json_files.append(os.path.join(foldername, filename))\n\n    return iversion_json_files\n\nif __name__ == \"__main__\":\n    cwd = os.path.dirname(__file__)\n    resource_root = os.path.join(cwd, \"mti\")\n    inventory_path = os.path.join(resource_root, \"inventories\", \"inv_surfquakecore.xml\")\n    data_dir_path = os.path.join(resource_root, \"waveforms\")\n    path_to_project = os.path.join(resource_root, \"project\")\n    path_to_configfiles = os.path.join(resource_root, \"list_earthquakes\")\n    working_directory = os.path.join(resource_root, \"working_directory\")\n    output_directory = os.path.join(resource_root, \"output_directory\")\n\n    # Load the Project\n    project_name = \"mti_project.pkl\"\n    path_to_project = os.path.join(path_to_project, project_name)\n    sp = SurfProject(path_to_project)\n    sp.search_files(verbose=True)\n    print(sp)\n\n\n    # Build the class\n    bic = BayesianIsolaCore(project=sp, inventory_file=inventory_path, output_directory=output_directory,\n                            save_plots=True)\n\n    # Run Inversion\n    bic.run_inversion(mti_config=path_to_configfiles)\n    print(\"Finished Inversion\")\n    iversion_json_files = list_files_with_iversion_json(output_directory)\n\n    for result_file in iversion_json_files:\n        result = read_isola_result(result_file)\n        print(result)\n\n    # Write a summury from all ouputs    \n    wm = WriteMTI(parsed_args.output_dir_path)\n    wm.mti_summary()\n</code></pre> <p>Alternatively, if you want you would prefer crate moment tensor config objects rather than point to a folder with .ini files. Then, crate objects like this:</p> <pre><code>mti_configs = [] # Create an empty list to storage mti configurations\n\ndate_str = \"28/02/2022 02:07:59.433\"\norigin_date = datetime.strptime(date_str, '%d/%m/%Y %H:%M:%S.%f')\n# still implementing test\nmti_config1 = MomentTensorInversionConfig(\n    origin_date=origin_date,\n    latitude=42.5414,\n    longitude=1.4505,\n    depth_km=5.75,\n    magnitude=3.0,\n    stations=[StationConfig(name=\"TEST1\", channels=[\"NNH\", \"NNZ\", \"NNE\"]), \n    StationConfig(name=\"TEST2\", channels=[\"NNH\", \"NNZ\", \"NNE\"])],\n    inversion_parameters=InversionParameters(\n        earth_model_file=\"earthmodel/Iberia.txt\",\n        location_unc=0.7,\n        time_unc=.2,\n        depth_unc=3.,\n        source_duration=2.0,\n        rupture_velocity=2500.,\n        min_dist=10.,\n        max_dist=300.,\n        source_type='PointSource'\n    ),\n)\n\n\nmti_cnfig2 = MomentTensorInversionConfig(....)\n........\n\nmti_configs = [mti_config1, mti_config2 .... ]\n</code></pre> <p>Then</p> <pre><code>for mti_config in list_of_mti_configs:\n    bic.run_inversion(mti_config=mti_config)\n\niversion_json_files = list_files_with_iversion_json(output_directory)\n\nfor result_file in iversion_json_files:\n    result = read_isola_result(result_file)\n    print(result)\n\nwm = WriteMTI(parsed_args.output_dir_path)\nwm.mti_summary()\n</code></pre>"},{"location":"picker/","title":"Phase Picker","text":"<p>The Picking algorythm of surfQuake uses the Deep Neural Network of Phasenet (Zhu and Beroza, 2019) to estimate the arrival times of P- and S-wave. The arrival times are saved as a csv file and in daily folders to be ready to be used by the associator. Example of csv header:</p> <pre><code>date,fname,year,month,day,net,station,flag,tt,date_time,weight,amplitude,phase\n20220131,CA.ARBS.P,2022,1,31,CA,ARBS,1,39383.88,2022-01-31T10:56:23.880000,0.5383206605911255,8557892.700195312,P\n20220131,CA.ARBS.S,2022,1,31,CA,ARBS,1,85480.59,2022-01-31T23:44:40.590000,0.30124416947364807,8481788.269042969,S\n</code></pre>"},{"location":"picker/#phase-picker-gui","title":"Phase Picker GUI","text":"<p>We start with the GUI. This is a screenshot of the Project GUI.</p> <p></p> <p>Be sure you have just created a Project or you have loaded one. Then click on Run Auto Pick. This action will start the phase picker and will save the output in Output Directory ready to be used in the associator toolbox and original_picks as csv file for direct reading.</p>"},{"location":"picker/#phase-picker-from-cli","title":"Phase picker from CLI","text":""},{"location":"picker/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake pick -f [path to your project file] -d [path to your pick saving directory] -p [P-wave threshoold] -s [S-wave threshold] --verbose\n</code></pre>"},{"location":"picker/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake pick -h\n</code></pre>"},{"location":"picker/#run-phase-picker-from-cli","title":"Run Phase Picker from CLI","text":"<pre><code>&gt;&gt; surfquake pick -f /test_surfquake_core/testing_data/projectssurfquake_project_new.pkl -d /test_surfquake_core/testing_data/picks -p 0.3 -s 0.3 --verbose\n</code></pre>"},{"location":"picker/#phase-picker-from-library","title":"Phase Picker from Library","text":""},{"location":"picker/#classes","title":"Classes","text":"<p><code>PhasenetISP</code></p> <pre><code>class PhasenetISP:\n    def __init__(files, batch_size=3, highpass_filter=0.5, min_p_prob=0.3, min_s_prob=0.3, min_peak_distance=50, amplitude=False):\n\n    \"\"\"\n\n    Main class to initialize the picker\n\n    :param files: Dictionary with kewords addressing to seismograms file path and their corresponding metadata (i.e. sampling rate).\n    :type SurfProject: required (see Project section)\n\n    :param batch_size: Determines the number of samples in each batch (larger batch size uses more memory but can provide more accurate updates)\n    :type float:\n\n    :param highpass_filter: Lower corner frequency of highpass filter to be applied to the raw seismogram. Set to 0 to do not apply any pre-filter\n    :type float:\n\n    :param min_p_prob: Probability threshold for P pick\n    :type float:\n\n    :param min_s_prob: Probability threshold for S pick\n    :type float:\n\n    :param min_peak_distance: Minimum peak distance\n    :type float:\n\n    :param amplitude: if return amplitude value\n    :type float:\n\n    :returns:\n    :rtype: :class:`surfquakecore.phasenet.phasenet_handler.PhasenetISP`\n\n    \"\"\"\n</code></pre> <p><code>PhasenetUtils</code></p>"},{"location":"picker/#methods","title":"Methods","text":"<p><code>phasenet</code></p> <pre><code># instance method\ndef phasenet(self):\n</code></pre> <p><code>PhasenetUtils.split_picks</code></p> <pre><code>@staticmethod\ndef split_picks(picks):\n    \"\"\"\n    :param picks: A DataFrame with all pick information\n    :type picks: Pandas DataFrame\n    \"\"\"\n</code></pre> <p><code>PhasenetUtils.convert2real</code></p> <pre><code>@staticmethod\ndef convert2real(picks, pick_dir: str):\n\"\"\"\n:param picks: picks is output from method split_picks in mseedutils\n:param pick_dir: directory outpur where phases are storaged\n:return:\n\"\"\"\n</code></pre> <p><code>PhasenetUtils.split_picks</code> <pre><code>@staticmethod\ndef save_original_picks(original_picks, original_p_dir):\n    \"\"\"\n\n    :param original_picks: picking output from phasenet (method split_picks in mseedutils)\n    :param original_p_dir: output to storage original_picks\n    :return:\n    \"\"\"\n</code></pre></p>"},{"location":"picker/#example-using-library","title":"Example using library","text":"<pre><code>import os\nfrom multiprocessing import freeze_support\nfrom surfquakecore.phasenet.phasenet_handler import PhasenetUtils\nfrom surfquakecore.phasenet.phasenet_handler import PhasenetISP\nfrom surfquakecore.project.surf_project import SurfProject\n\n### Set Paths to project file and output folder ###\npath_to_project = \"/Volumes/LaCie/test_surfquake_core/project/surfquake_project.pkl\"\noutput_picks = '/Volumes/LaCie/test_surfquake_core/test_picking'\n\nif __name__ == '__main__':\n    freeze_support()\n\n    # Load project\n    sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n\n    # Instantiate the class PhasenetISP\n    phISP = PhasenetISP(sp_loaded.project, amplitude=True, min_p_prob=0.90, min_s_prob=0.65)\n\n    # Running Stage\n    picks = phISP.phasenet()\n\n    \"\"\" PHASENET OUTPUT TO REAL INPUT \"\"\"\n\n    picks_results = PhasenetUtils.split_picks(picks)\n    PhasenetUtils.convert2real(picks_results, output_picks)\n    PhasenetUtils.save_original_picks(picks_results, output_picks)\n</code></pre>"},{"location":"project/","title":"Create your project","text":"<p>In surfQuake a project is simply a python object that can store in its attributes the path to valid seismogram files plus the associated metadata. This strategy allows to proceed with fast filters or join different projects. Project is the necessary input for the toolboxes Picker, Associator, Event Locator, Seismic Source and MTI.</p> <p>Here we will explain how the user can manage a project and be ready to proceed with the rest of toolboxes.</p>"},{"location":"project/#project-gui","title":"Project GUI","text":"<p>We start with the GUI. This is a screenshot of the Project GUI.</p> <p></p> <p>First, you need to choose between: </p> <ul> <li>Search files using Regular Expressions: Click in this button will open a window explorer to select the available files based on the filter edit line. In the example (.HHZ) and (EMUR*). Please set to blank space if you do not desire apply filters inside the window explorer. Then just select files and accept. The project will be automatically generated. </li> <li>Project Parth Files: This option is intendeed to let surfQuake search for valid seismogram files from a root folder in ahead. Optionally check Filter Time Spam and/or Filter Keys to include seismograms files that only fullfills the filter.</li> </ul> <p>Second:</p> <ul> <li>Save Project It is very remmendable to save the project. So, Proceed to give a name to the project and save it pressing Save Project for later using.</li> </ul> <p>Third:</p> <ul> <li>Load Project This action will open a window explorer so that you can select a project file previously saved and loaded. This will let you go ahead with the following toolboxes such as Picking Phases.</li> </ul> <p>Finally:</p> <ul> <li>Metadata: Metadata file with the in there is information structured as a dictionary nets/stations/channels. Personally, the best way to make your own metadata file is using either the java software PDCC or going to the API Station Management Portal. We also give a tool to make your metadata from a stations file and response files here.</li> </ul> <p></p>"},{"location":"project/#project-from-cli","title":"Project from CLI","text":""},{"location":"project/#overview","title":"Overview","text":"<p>This command allows you to create a seismic project, which is essentially a dictionary storing the paths to seismogram files along with their corresponding metadata.</p>"},{"location":"project/#usage","title":"Usage","text":"<pre><code>&gt;&gt;surfquake project -d [path to data files] -s [path to save directory] -n [project name] --verbose\n</code></pre>"},{"location":"project/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake project -h\n</code></pre>"},{"location":"project/#create-project-example-from-cli","title":"Create Project example from CLI","text":"<p>In your termina, activate sufquake enviroment to have access to the commands. Then:</p> <pre><code>&gt;&gt; surfquake project -d /Volumes/LaCie/test_surfquake_core/testing_data -s /Volumes/LaCie/test_surfquake_core/testing_data/projects -n /surfquake_project_new.pkl --verbose\n</code></pre>"},{"location":"project/#project-from-library","title":"Project from library","text":""},{"location":"project/#classes","title":"Classes","text":"<p>In this section, we will explain the class SurfProject and we will explain how to manage your project from a simple example:</p> <p><code>SurfProject</code></p> <pre><code>class SurfProject:\n\n    def __init__(self, root_path: Union[str, List[str]]):\n\n        \"\"\"\n\n        SurfProject class is designed to be able to storage the path to seismograms\n        files plus the file metadata information (i.e. sampling_rate, starttime...)\n\n        Attributes:\n        - root_path (str): The root path to the folder where the user have the data files.\n\n        Methods:\n        - __init__(root_path): Initialize a new instance of MyClass.\n        - load_project(path_to_project_file: str): Load a project from a file storage in hard-drive\n        - save_project(path_file_to_storage: str): Saves a project as a pickle file in hard-drive\n        - search_files(verbose=True, **kwargs): Create a project. It can be used filters by nets,\n        stations, channels selection and/or filter by timestamp\n        - filter_project_keys(**kwargs): Filter a project (once is crated) using regular expressions.\n        \"\"\"\n</code></pre>"},{"location":"project/#methods","title":"Methods","text":"<p><code>search_files</code></p> <pre><code>    def search_files(self, format=\"NONE\", verbose=True, **kwargs):\n\n        \"\"\"\n        Args:\n\n        - verbose (bool): Description of arg1.\n        - nets (str): String with the name of selected nets to be filtered (i.e., \"WM,ES\")\n        - stations (str): String with the name of selected stations to be filtered (i.e., \"ARNO,UCM,EMAL\")\n        - channels (str): String with the name of selected channels to be filtered (i.e., \"HHN,HHZ,HHE\")\n        - starttime (str \"%Y-%m-%d %H:%M:%S\" ): String with the reference starttime, upper time spam threshold\n        (i.e.,\"2023-12-10 00:00:00\")\n        - endtime (str \"%Y-%m-%d %H:%M:%S\" ): String with the reference endtime, lower time spam threshold\n        (i.e.,\"2023-12-23 00:00:00\")\n\n        Returns:\n        - type: Description of the return value.\n        \"\"\"\n</code></pre> <p><code>filter_project_keys</code></p> <pre><code>    def filter_project_keys(self, **kwargs):\n\n        \"\"\"\n        Args:\n        - net (str): String with the name of selected nets to be filtered (i.e., \".\")\n        - station (str): String with the name of selected stations to be filtered (i.e., \"ARNO|UCM|EMAL\")\n        - channel (str): String with the name of selected channels to be filtered (i.e., \"HH.\")\n        \"\"\"\n</code></pre> <p><code>filter_project_time</code></p> <pre><code>    def filter_project_time(self, starttime: str, endtime: str):\n\n        \"\"\"\n        - starttime (str, \"%Y-%m-%d %H:%M:%S\"): String with the reference starttime, upper time spam threshold\n        (i.e., \"2023-12-10 00:00:00\")\n\n        - endtime (str, \"%Y-%m-%d %H:%M:%S\" ): String with the reference endtime, lower time spam threshold\n        (i.e., \"2023-12-23 00:00:00\")\n\n        \"\"\"\n</code></pre> <p><code>save_project</code></p> <pre><code>def save_project(self, path_file_to_storage: str)-&gt;bool\n# Saves the project object as a pickle file.\n</code></pre> <p><code>load_project</code></p> <pre><code>def load_project(path_to_project_file: str):\n</code></pre>"},{"location":"project/#attibutes","title":"Attibutes","text":"<pre><code>project :Dict\ndata_files :List\n</code></pre> <p>Next, the example of using this class and its methods. This example script is available in SurfQuakeCore/examples/manage_project_new.py</p> <pre><code>from multiprocessing import freeze_support\nfrom surfquakecore.project.surf_project import SurfProject\nimport time\n\npath_to_data = \"/Volumes/LaCie/test_surfquake_core/testing_data\"\npath_to_project = \"/Volumes/LaCie/test_surfquake_core/testing_data/projects/surfquake_project_new.pkl\"\n\nif __name__ == '__main__':\n\n    freeze_support()\n    sp = SurfProject(path_to_data)\n    #sp.search_files(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\", stations=\"SALF,VALC\", channels=\"HHZ\")\n    sp.search_files(verbose=False)\n    #sp_original_project = copy.copy()\n    sp.filter_project_keys(station=\"SALF|VALC|CEST\")\n    sp_original1 = sp.copy()\n    sp_original1.filter_project_keys(station=\"SALF\")\n    sp_original2 = sp.copy()\n    sp_original2.filter_project_keys(station=\"VALC\")\n\n    sp_join = sp_original1 + sp_original2\n    print(\"With no filter\")\n    print(sp_join)\n    sp_join.filter_project_time(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\")\n    print(\"With filter\")\n    print(sp_join)\n    sp_join.save_project(path_file_to_storage=path_to_project)\n    time.sleep(5)\n    sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n    print(sp_loaded)\n</code></pre> <p>The first step is create the object from the class SurfProject </p> <pre><code>sp = SurfProject\n</code></pre> <p>The necessary input to create the sp object is the root path where you have storage the seismogram files. Then, you can proceed to apply the method \"search_files\". This method includes the possibility of filter the inclusion of files inside the project.</p> <pre><code>sp.search_files(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\", stations=\"SALF,VALC\", channels=\"HHZ\")\nprint(sp) # To see the contain of the project\n</code></pre> <p>Additionally, once the project has been created, you can also filter it by using \u00b4regular expressions\u00b4 net, station, channel using:</p> <p>Note: some util Regex info at Wiki Regex and Python keywords <pre><code>sp.filter_project_keys(station=\"SALF|VALC|CEST\")\n</code></pre></p> <p>or filterintg the time spam using:</p> <pre><code>sp_join.ilter_project_time(starttime=\"2022-01-30 23:55:00\", endtime=\"2022-02-01 00:30:00\")\n</code></pre> <p>Adding projects using \"+\" symbol</p> <pre><code>sp_original1 = sp.copy()\nsp_original1.filter_project_keys(station=\"SALF\")\nsp_original2 = sp.copy()\nsp_original2.filter_project_keys(station=\"VALC\")\n\nsp_join = sp_original1 + sp_original2\n</code></pre> <p>Finally, you can save the project by, <pre><code>sp_join.save_project(path_file_to_storage=path_to_project)\n</code></pre> and loading it</p> <pre><code>sp_loaded = SurfProject.load_project(path_to_project_file=path_to_project)\n</code></pre>"},{"location":"source/","title":"Source Parameters","text":"<p>The tool Source Parameters is designed to estimate events source parameters (i.e., Mw, ML, seismic moment, corner frequency, radiated energy, source size and stress drop) and the attenuation parameters (t-star, quality factor). It is based in the implementation of Satrinano et al., 2023. A detailed theoretical background can be found here</p>"},{"location":"source/#source-parameters-gui","title":"Source Parameters GUI","text":"<ul> <li>Time Window Parameters<ul> <li>P- and S-wave tolerance: Difference in seconds from the detected wave and the theroretical arrival time.</li> <li>noise_pre_time window: Window lenght before the first arrival time</li> <li>signal window: Window leght of signal to be analyse after first phase arrival time</li> <li>spectral window: Time window before the first arrival time</li> </ul> </li> <li>Source Parameters<ul> <li>Source Density: Density of the rock in the source.</li> <li>rpp: Radiation pattern coefficient for the P-wave</li> <li>rps: Radiation pattern coefficient for the S-wave</li> <li>Geometrical Spreading Correction: Spectra will be multiplied by this value to correct for the lost amplitude<ul> <li>r_power_n: geom_spread_n_exponent = 1 (default, body wave in a homogeneous full-space), 0.5 (surface wave in a homogeneous half-space)</li> <li>boatwright: \"r\" (body waves) geometrical spreading for hypocentral distances below a cutoff distance; frequency-dependent geometrical spreading above the cutoff distance (Boatwright et al., 2002).<ul> <li>Geometrical spreading cutoff distance: Geometrical spreading cutoff distance, in km, for the \"boatwright\" model</li> </ul> </li> </ul> </li> </ul> </li> <li>Local Magnitude: Local magnitude parameters: ml = log10(A) + a * log10(R/100) + b * (R-100) + c, where A is the maximum W-A amplitude (in mm) and R is the hypocentral distance (in km)</li> </ul>"},{"location":"source/#config-file","title":"Config file","text":"<pre><code># GENERAL PARAMETERS --------\n# All the fields are optional.\n# The filled in fields will be written to output files.\n# Author information\nauthor_name = SurfQuakeCore\nauthor_email = https://projectisp.github.io/ISP_tutorial.github.io/\n# Agency information\nagency_full_name = Spanish Navy Observatory\nagency_short_name = ROA\nagency_url = https://armada.defensa.gob.es/ArmadaPortal/page/Portal/ArmadaEspannola/cienciaobservatorio/prefLang-es/02InfoGeneral\n# -------- GENERAL PARAMETERS\n\n# TRACE AND METADATA PARAMETERS --------\n# Channel naming for mis-oriented channels (vertical, horiz1, horiz2):\n# Example:\n#   mis_oriented_channels = Z,1,2\nmis_oriented_channels = Z, 1, 2\n\n# Option to specify non standard instrument codes (e.g., \"L\" for accelerometer)\ninstrument_code_acceleration = None\ninstrument_code_velocity = None\n\n# For more complex network.station.location.channel (SCNL) naming scenarios,\n# you can provide a file, in json format, with traceid (SCNL) mapping\ntraceid_mapping_file = None\n\n# List of traceids to ignore.\n# Use network.station.location.channel; wildcards are accepted\n# Example:\n#   ignore_traceids = FR.CIEL.*.*, AM.RA0D3.00.*\nignore_traceids = None\n\n# List of traceids to use.\n# Use network.station.location.channel; wildcards are accepted\n# Example:\n#   use_traceids = FR.CIEL.*.*, AM.RA0D3.00.*\nuse_traceids = None\n\n# Epicentral distance ranges (km) to select stations to be processed.\n# Use a list of alternating min/max values, ex.:\n#   to only use stations between 0 and 100 km:\n#       epi_dist_ranges = 0, 100\n#   to avoid teleseismic distances between 14\u00c2\u00b0 (1300 km) and 29\u00c2\u00b0 (3200 km)\n#   where the P-wave undergoes travel time triplications:\n#       epi_dist_ranges = 0, 1300, 3200, 999999\n# Leave it to None to use all stations.\nepi_dist_ranges = 0, 400.0\n\n# Directory or single file name containing station metadata\n# (instrument response and station coordinates).\n# Note: this parameter can be overridden by the command line option\n#       with the same name.\n# Station metadata files can be in one of the following formats:\n#   StationXML, dataless SEED, SEED RESP, PAZ (SAC polezero format)\n# Notes:\n# 1. SourceSpec will not enter in subdirectories of the given directory\n#    (only one level allowed)\n# 2. Traceid for PAZ files is specified through their name.\n#    The traceid (network.station.location.channel) must be in the last four\n#    fields (separated by a dot \".\") before the file suffix (which can be\n#    \".paz\", \".pz\", or no suffix).\n#    Example:\n#      PREFIX.NET.STA.LOC.CHAN.paz\n#    or (no prefix):\n#      NET.STA.LOC.CHAN.paz\n#    or (no prefix and no suffix):\n#      NET.STA.LOC.CHAN\n# 3. If no traceid is specified through the PAZ file name, then it is assumed\n#    that this is a generic PAZ, valid for all the stations that do not have\n#    a specific PAZ. Use \"trace_units\" below to specify the units of the\n#    generic PAZ.\n# 4. SEED RESP and PAZ files do not contain station coordinates, which\n#    should therefore be in the trace header (traces in SAC format)\n#station_metadata = inventory.xml\n\n# It is also possible to provide a constant sensitivity (i.e., flat instrument\n# response curve) as a numerical value or a combination of SAC header fields\n# (in this case, traces must be in SAC format).\n# This parameter overrides the response curve computed from station_metadata.\n# Leave it to None to compute instrument response from station_metadata.\n# Examples:\n#  sensitivity = 1\n#  sensitivity = 1e3\n#  sensitivity = resp0\n#  sensitivity = resp1*resp2\n#  sensitivity = user3/user2\nsensitivity = None\n\n# SQLite database file for storing output parameters (optional):\ndatabase_file = source_spec.sqlite\n\n# Correct_instrumental_response (optional, default=True):\ncorrect_instrumental_response = True\n\n# Trace units.\n# Leave it to 'auto' to let the code decide, based on instrument type.\n# Manually set it to 'disp', 'vel' or 'acc' if you have already preprocessed\n# the traces.\ntrace_units = auto\n# -------- TRACE AND METADATA PARAMETERS\n\n\n# TIME WINDOW PARAMETERS --------\n# P and S wave velocity (in km/s) for travel time calculation\n# (if None, the global velocity model 'iasp91' is used)\n# Theoretical P or S arrival times are used when a manual P or S pick is not\n# available, or when the manual P or S pick is too different from the\n# theoretical arrival (see 'p_arrival_tolerance' and 's_arrival_tolerance'\n# below).\nvp_tt = None\nvs_tt = None\n# As an alternative, a directory containing NonLinLoc travel time grids\n# can be specified and values defined above will be ignored.\n# Note that reading NonLinLoc grids takes time. For simple 1D models, you\n# can speed up considerably the process using a generic station\n# named \"DEFAULT\". The coordinates of this default station are not important,\n# since they will be superseded by each station's coordinates.\nNLL_time_dir = None\n\n# Arrival tolerances (in seconds) to accept a manual P or S pick\np_arrival_tolerance = 8.0\ns_arrival_tolerance = 8.0\n\n# Start time (in seconds) of the noise window, respect to the P arrival time\nnoise_pre_time = 15.0\n\n# Start time (in seconds) of the signal window, respect to the P or S arrival\n# times (see \"wave_type\" below)\nsignal_pre_time = 1.0\n\n# Length (in seconds) for both noise and signal windows\nwin_length = 10.0\n# -------- TIME WINDOW PARAMETERS\n\n\n# SPECTRUM PARAMETERS --------\n# Wave type to analyse: 'P', 'S', 'SH' or 'SV'\n# If 'SH' or 'SV' are selected, traces are rotated in the radial-transverse\n# system. Transverse component is used for 'SH', radial component (and\n# optionally the vertical component, see 'ignore_vertical' below) is used\n# for 'SV'\nwave_type = S\n\n# Integrate in time domain (default: integration in spectral domain)\ntime_domain_int = False\n\n# Ignore vertical components when building S or SV spectra\n# Note: this option has no effect when 'wave_type' is 'P' (the vertical\n# component is not ignored) and when 'wave_type' is 'SH' (the vertical\n# component is not needed)\nignore_vertical = False\n\n# Taper half width: between 0 (no taper) and 0.5\ntaper_halfwidth = 0.05\n\n# Spectral window length (seconds)\n# Signal is tapered, and then zero padded to\n# this window length, so that the spectral\n# sampling is fixed to 1/spectral_win_length.\n# Comment out (or set to None) to use\n# signal window as spectral window length.\nspectral_win_length = None\n\n# Spectral smoothing window width in frequency decades\n# (i.e., log10 frequency scale).\n# Example:\n#  spectral_smooth_width_decades=1 means a width of 1 decade\n#  (generally, too large, producing a spectrum which is too smooth).\n#  spectrum(f0) is smoothed using values between f1 and f2, so that\n#  log10(f1)=log10(f0)-0.5 and log10(f2)=log10(f0)+0.5\n#    i.e.,\n#  f1=f0/(10^0.5) and f2=f0*(10^0.5)\n#    or,\n#  f2/f1=10 (1 decade width)\n# Default value of 0.2 is generally a good choice\nspectral_smooth_width_decades = 0.2\n\n# Residuals file path\n# (a pickle file with the mean residuals per station,\n# used for station correction):\nresiduals_filepath = None\n\n# Remove the signal baseline after instrument correction and before filtering\nremove_baseline = False\n\n# Band-pass frequencies (Hz) for accelerometers, velocimeters\n# and displacement sensors.\n# Use bp_freqmin_STATION and bp_freqmax_STATION to provide\n# filter frequencies for a specific STATION code.\n# TODO: calculate from sampling rate?\nbp_freqmin_acc = 0.001\nbp_freqmax_acc = 50.0\nbp_freqmin_shortp = 0.01\nbp_freqmax_shortp = 40.0\nbp_freqmin_broadb = 0.001\nbp_freqmax_broadb = 40.0\nbp_freqmin_disp = 0.5\nbp_freqmax_disp = 40.0\n\n# Spectral windowing frequencies (Hz) for accelerometers, velocimeters\n# and displacement sensors.\n# (spectra will be cut between these two frequencies)\n# Use freq1_STATION and freq2_STATION to provide\n# windowing frequencies for a specific STATION code.\nfreq1_acc = 0.05\nfreq2_acc = 30.0\nfreq1_shortp = 0.05\nfreq2_shortp = 30.0\nfreq1_broadb = 0.05\nfreq2_broadb = 30.0\nfreq1_disp = 0.5\nfreq2_disp = 30.0\n# -------- SPECTRUM PARAMETERS\n\n\n# SIGNAL/NOISE PARAMETERS --------\n# Minimum rms (in trace units before instrument corrections)\n# to consider a trace as noise\nrmsmin = 0.0\n\n# Time domain S/N ratio min\nsn_min = 1.0\n\n# Clipping detection algorithm\n# Options:\n#  - 'none': no clipping detection\n#  - 'clipping_score': compute a clipping score for each trace, based on the\n#    shape of the kernel density estimation of the trace amplitude values.\n#    A high clipping score will be obtained for traces with a high number of\n#    samples whose amplitude is close to the trace highest or lowest\n#    amplitude values. Clipping scores for each trace are printed on the\n#    terminal and in the log file.\n#    Note: if \"remove_baseline\" is True (see above), clipping scores are\n#    computed on the baseline-corrected signal.\n#  - 'clipping_peaks': count the number of peaks in the kernel density\n#    estimation of the trace amplitude values. The trace is considered clipped\n#    if at least one peak is found within the trace highest or lowest amplitude\n#    values. Kernel density peaks for each trace are printed on the terminal\n#    and in the log file.\nclipping_detection_algorithm = clipping_score\n# Plot a debug figure for each trace with the results of the clipping algorithm\n# Note: the figures are always shown, even if \"plot_show\" is False (see below)\nclipping_debug_plot = False\n# Threshold for the 'clipping_score' algorithm (between 0 and 100).\n# A value of 100 means no clipping detection.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_score'.\nclipping_score_threshold = 10.0\n# Sensitivity for the 'clipping_peaks' algorithm (between 1 and 5).\n# Higher values mean more peaks are detected.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_peaks'.\n#clipping_peaks_sensitivity = 3\n# Trace amplitude percentile for the 'clipping_peaks' algorithm (between 0\n# and 100). Example:\n#   clipping_peaks_percentile = 10\n# means that the 10% highest and lowest values of the trace amplitude will be\n# checked for clipping.\n# A value of 0 means that no clipping check will be performed.\n# This parameter is ignored if \"clipping_detection_algorithm\" is not set to\n# 'clipping_peaks'.\n#clipping_peaks_percentile = 10.0\n\n# Maximum gap length for the whole trace, in seconds\ngap_max = None\n# Maximum overlap length for the whole trace, in seconds\noverlap_max = None\n\n# Spectral S/N ratio min, below which a spectrum will be skipped\nspectral_sn_min = 10.0\n# Frequency range (Hz) to compute the spectral S/N ratio\n# (comment out or use None to indicate the whole frequency range)\n# Example:\n#  spectral_sn_freq_range = 0.1, 2\nspectral_sn_freq_range = None\n# -------- SIGNAL/NOISE PARAMETERS\n\n\n# SPECTRAL MODEL PARAMETERS --------\n# Layer top depths (km, positive down), for layered models (see below)\n#  Note: generally, the first layer top depth should be 0 or a negative value\n#layer_top_depths = 0, 3\n# P and S wave velocity close to the source (km/s)\n# It can be a single value or a list of values (layered model)\n# Set to None to use velocity from the global Earth model 'iasp91'\n#   Note: specifying a layered model is useful when the same config file is\n#   used for several SourceSpec runs with sources at different depths\n#vp_source = 4.5, 5.5\n#vs_source = 2.5, 3.2\nvp_source = 5.0\nvs_source = 2.9\n# P and S wave velocity close to the stations (km/s)\n# If set to None, velocity values close to the source will be used\nvp_stations = 4.5\nvs_stations = 2.5\n# As an alternative, a directory containing a NonLinLoc velocity model can be\n# specified. In this case, the values provided above will be ignored\nNLL_model_dir = None\n# Density close to the source (kg/m3)\n# It can be a single value or a list of values (layered model)\n# Set to None to use density from the global Earth model 'iasp91'\n#   Note: specifying a layered model is useful when the same config file is\n#   used for several SourceSpec runs with sources at different depths\n#rho_source = 2400, 2500\nrho_source = 2400\n# Density close to the stations (kg/m3)\n# If set to None, density value close to the source will be used\n#rho_stations = 2400.0\n# Geometrical spreading correction of wave amplitude.\n# Spectra will be multiplied by this value to correct for the lost amplitude.\n# Possible options are:\n#    'r_power_n':   \"r\" to the power of \"n\" (r\u00e2\u0081\u00bf).\n#                   You must provide the value of the exponent \"n\"\n#                   (see \"geom_spread_n_exponent\" below).\n#    'boatwright':  \"r\" (body waves) geometrical spreading for hypocentral\n#                   distances below a cutoff distance; frequency-dependent\n#                   geometrical spreading above the cutoff distance (Boatwright\n#                   et al., 2002). You must provide the cutoff distance (see\n#                   \"geom_spread_cutoff_distance\" below). This coefficient can\n#                   be a valid choice for regional distances (up to 200 km),\n#                   where S-waves, Lg waves and surface waves are mixed.\ngeom_spread_model = r_power_n\n# Exponent \"n\" for the \"r_power_n\" geometrical spreading coefficient (positive\n# float). Examples:\n#   geom_spread_n_exponent = 1 (default, body wave in a homogeneous full-space)\n#   geom_spread_n_exponent = 0.5 (surface wave in a homogeneous half-space)\ngeom_spread_n_exponent = 1.0\n# Geometrical spreading cutoff distance, in km, for the \"boatwright\" model:\ngeom_spread_cutoff_distance = 100.0\n# Minimum distance (in km) to use a teleseismic geometrical spreading\n# model. Above this distance, the model from Okal (1992) for body waves\n# spreading in a spherically symmetric Earth will be used.\ngeom_spread_min_teleseismic_distance = 500.0\n# P-wave average radiation pattern coefficient:\nrpp = 0.52\n# S-wave average radiation pattern coefficient:\nrps = 0.62\n# Radiation pattern coefficient from focal mechanism, if available.\n#   Note: radiation pattern is computed for the first arriving phase and might\n#   not be correct for windows involving multiple phase arrivals (e.g.,\n#   Lg waves, surface waves at regional distances, depth phases at teleseismic\n#   distances)\nrp_from_focal_mechanism = False\n# \"kp\" and \"ks\" coefficients to compute source radius a from the P-wave\n# corner frequency fc_p or the S-wave corner frequency fc_s and the shear\n# wave speed beta (\"vs_source\"):\n#\n#   a = kp * beta / fc_p\n#   a = ks * beta / fc_s\n#\n# (Madariaga, 2009; Kaneko and Shearer, 2014)\n#\n# The default value for S-waves is \"ks = 0.3724\", obtained by Brune (1970)\n# for a static circular crack.\n# Other values are discussed in Kaneko and Shearer (2014) for a dynamic\n# circular crack, as a function of the ratio Vr/beta, where Vr is the rupture\n# speed:\n#\n#   Vr/beta  kp(K&amp;S)   ks(K&amp;S)   kp(Mada)   ks(Mada)   kp(S&amp;H)   ks(S&amp;H)\n#   0.9      0.38      0.26      0.32       0.21       0.42      0.29\n#   0.8      0.35      0.26                            0.39      0.28\n#   0.7      0.32      0.26                            0.36      0.27\n#   0.6      0.30      0.25                            0.34      0.27\n#   0.5      0.28      0.22                            0.31      0.24\n#\n#   K&amp;S: Kaneko and Shearer (2014)\n#   Mada: Madariaga (1976)\n#   S&amp;H: Sato and Hirasawa (1973)\n#kp = 0.38\n#ks = 0.3724\n# -------- SPECTRAL MODEL PARAMETERS\n\n\n# INVERSION PARAMETERS --------\n# Weighting type: 'noise', 'frequency', 'inv_frequency' or 'no_weight'\n#   'noise':         spectral signal/noise ratio weighting\n#   'frequency':     a constant weight is applied for f&lt;=f_weight\n#                    a weight of 1 is used for f&gt;f_weight\n#                    (see \"f_weight\" and \"weight\" below)\n#   'inv_frequency': weight is computed as 1/(f-f0+0.25)**0.25 for f&lt;=f1,\n#                    weight is 0 for f&lt;f0 and f&gt;f1.\n#                    f0 and f1 are the first and last frequencies where\n#                    spectral signal/noise ratio is above 3, or the first and\n#                    last frequencies of the entire spectrum if no noise window\n#                    is available\n#   'no_weight':     no weighting\nweighting = noise\n# Parameters for 'frequency' weighting (ignored for the other weighting types):\n#   weight for f&lt;=f_weight (Hz)\n#   1      for f&gt; f_weight (Hz)\nf_weight = 7.0\nweight = 10.0\n\n# Inversion algorithm:\n# TNC: truncated Newton algorithm (with bounds)\n# LM: Levenberg-Marquardt algorithm\n# (warning: Trust Region Reflective algorithm will be used instead if\n#  bounds are provided)\n# BH: basin-hopping algorithm\n# GS: grid search\n# IS: importance sampling of misfit grid, using k-d tree\ninv_algorithm = GS\n\n# Mw initial value and bounds.\n# Set to True to use the magnitude (or scalar moment) from event file as\n# initial Mw value for the inversion, instead of computing it from the average\n# of the spectral plateau.\n# If the event file does not contain a magnitude value or a scalar moment,\n# then this parameter is ignored\n# Mw_0_from_event_file = False\n# Allowed variability for Mw in the inversion\n# (expressed as a fraction of Mw_0, between 0 and 1).\n# This parameter is interpreted differently, depending on whether\n# Mw_0_from_event_file is True or False:\n#   - If Mw_0_from_event_file is True, then Mw_variability is interpreted as\n#     the allowed variability around the Mw value provided in the event file.\n#   - If Mw_0_from_event_file is False, then the Mw bounds are defined as\n#       Mw_min = min(Mw(f))*(1-Mw_0_variability)\n#       Mw_max = max(Mw(f))*(1+Mw_0_variability),\n#     where Mw(f) is the low frequency spectral plateau in magnitude units.\n#     If noise weighting is used, frequencies for which\n#     S/N(f) &lt; 0.5*max(S/N(f)) will be ignored, where S/N(f) is the spectral\n#     signal to noise ratio.\nMw_0_variability = 0.1\n\n# Bounds for fc (Hz)\n# Specify bounds as a list, ex.:\n#   fc_min_max = 0.1, 40\n# Note:\n#    If not specified, fc bounds will be autoset to fc0/10 and fc0*10, i.e. two\n#    decades around fc0. The value of fc0 is set as the first maximum of\n#    spectral S/N (noise weighting), or at \"f_weight\" (frequency weighting),\n#    or at frequency where weight is 30% below the maximum (inverse-frequency\n#    weighting) or at half of the frequency window (no weighting)\nfc_min_max = 0.05, 50.0\n\n# Initial value and bounds for t_star (seconds)\nt_star_0 = 0.045\n# Try to invert for t_star_0.\n# If False, then the fixed t_star_0 defined above will be used.\n# If the inverted t_star_0 is non-positive, then fixed t_star_0 will be used\ninvert_t_star_0 = False\n# Allowed variability around inverted t_star_0 in the inversion\n# (expressed as a fraction of t_star_0, between 0 and 1).\n# If the inverted t_star_0 is non-positive, then t_star_min_max is used\n# (see below).\nt_star_0_variability = 0.1\n# t_star_min_max does not supersede t_star_0_variability\nt_star_min_max = 0.001, 0.2\n# optional : Qo bounds (converted into t_star bounds in the code).\n# (comment out or use None to indicate no bound)\n# Note: if you want to explore negative t_star values, you have to specify\n# -Qo_min, Qo_min. This because t_star is proportional to 1/Qo.\n# Example, for searching only positive t_star values:\n#   Qo_min_max = 10, 1000\n# If you want to search also negative t_star values:\n#   Qo_min_max = -10, 10\nQo_min_max = None\n# -------- INVERSION PARAMETERS\n\n# POST-INVERSION PARAMETERS --------\n# Post-inversion bounds: use this bounds to reject certain inversion\n# results, per station.\n# Sometimes it is better to be more permissive with inversion parameters and\n# reject \"bad\" solutions after the inversion, rather than forcing the\n# inversion to converge within strict bounds.\n# fc bounds, in Hz\npi_fc_min_max = None\n# t_star bounds, in s\npi_t_star_min_max = None\n# Static stress drop bounds, in MPa\n# pi_ssd_min_max = None\n# Maximum acceptable misfit between inverted and observed spectrum\npi_misfit_max = None\n# -------- POST-INVERSION PARAMETERS\n\n\n# RADIATED-ENERGY PARAMETERS --------\n# Maximum frequency (Hz) to measure radiated energy Er\n# Set it to None to use the whole spectrum, i.e. up to the \"freq2_*\"\n# windowing frequency (see above).\n# The finite-band correction of Di Bona &amp; Rovelli (1988) will be applied\n# to account for the missing energy above the maximum frequency.\nmax_freq_Er = None\n# -------- RADIATED-ENERGY PARAMETERS\n\n\n# LOCAL MAGNITUDE PARAMETERS --------\ncompute_local_magnitude = True\n# Local magnitude parameters:\n#   ml = log10(A) + a * log10(R/100) + b * (R-100) + c\n# where A is the maximum W-A amplitude (in mm)\n# and R is the hypocentral distance (in km)\n# Default values (for California) are:\n#   a = 1., b = 0.00301, c = 3.\na = 1.0\nb = 0.00301\nc = 3.0\n# Band-pass filtering frequencies (Hz) for local magnitude\nml_bp_freqmin = 0.1\nml_bp_freqmax = 20.0\n# -------- LOCAL MAGNITUDE PARAMETERS\n\n# AVERAGES PARAMETERS --------\n# Reject outliers before averaging, using the IQR method.\n# IQR is the interquartile range Q3-Q1, where Q1 is the 25% percentile\n# and Q3 is the 75% percentile.\n# Values that are smaller than (Q1 - nIQR*IQR) or larger than (Q3 + nIQR*IQR)\n# will be rejected as outliers.\n# Set nIQR to None to disable outlier rejection.\n# Note: this parameter also controls the position of \"whiskers\" on the source\n# parameter box plots.\nnIQR = 1.5\n# -------- AVERAGES PARAMETERS\n\n\n# PLOT PARAMETERS --------\n# Show interactive plots (slower)\nplot_show = False\n# Save plots to disk\nplot_save = True\n# Plot file format: 'png', 'pdf' or 'pdf_multipage'\nplot_save_format = png\n# Plots an extra synthetic spectrum with no attenuation\nplot_spectra_no_attenuation = True\n# Plots an extra synthetic spectrum with no fc\nplot_spectra_no_fc = False\n# Max number of rows in plots\nplot_spectra_maxrows = 3\nplot_traces_maxrows = 3\n# Plot ignored traces (low S/N)\nplot_traces_ignored = True\n# Plot ignored spectra (low S/N)\nplot_spectra_ignored = True\n# Plot station map\nplot_station_map = False\n# Plot station names on map\nplot_station_names_on_map = True\n# Text size for station names\nplot_station_text_size = 8.0\n# Coastline resolution\n# Use None to let the code autoset the coastline resolution.\n# Otherwhise choose one of: 'full', 'high', 'intermediate', 'low' or 'crude'\nplot_coastline_resolution = None\n# Zoom level for map tiles\n# Use None to let the code autoset the zoom level\n# Otherwhise choose an integer beteen 1 (minimum zoom) and 18 (maximum zoom)\n# Note: for zoom levels larger than 11, some map tiles could be missing\nplot_map_tiles_zoom_level = None\n# -------- PLOT PARAMETERS\n\n\n# HTML REPORT --------\n# Generate an HTML page summarizing the results of this run\nhtml_report = True\n# Link to event page. If set, the event ID on the HTML page will be a link to\n# the event page. Use $EVENTID to indicate the current event ID.\n# Example:\n#   event_url = https://earthquake.usgs.gov/earthquakes/eventpage/$EVENTID/executive\nevent_url = https://projectisp.github.io/ISP_tutorial.github.io//$EVENTID\n# -------- HTML REPORT\n\n\n# QUAKEML PARAMETERS ----------------\n# Parameters for QuakeML output.\n#\n# A QuakeML file will be generated only if QuakeML is used for input.\n# The output file will be based on the input file, with additional information\n# on seismic moment, Mw and source parameters computed by SourceSpec.\n# Note: if you don't understand the parameters below, then probably you\n# don't need QuakeML output and you can leave all the parameters to their\n# default value\n\n# Set SourceSpec Mw as preferred\nset_preferred_magnitude = True\n# Base for all the object ids (smi)\nsmi_base = smi:local\n# String to strip from the Origin id when constructing the\n# Magnitude and stationMagnitude ids.\nsmi_strip_from_origin_id = \"\"\n# Template for the Magnitude object id (smi).\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_magnitude_template = \"$SMI_BASE/Magnitude/Origin/$ORIGIN_ID#sourcespec\"\n# Template for the stationMagnitude object id (smi).\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\n# Use $SMI_MAGNITUDE_TEMPLATE to reuse the template for Magnitude object\n# Use $WAVEFORM_ID to indicate the id of the associated waveform.\nsmi_station_magnitude_template = \"$SMI_MAGNITUDE_TEMPLATE#$WAVEFORM_ID\"\n# Template for the MomentTensor object id (smi) which is used to store\n# the scalar moment value.\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_moment_tensor_template = \"$SMI_BASE/MomentTensor/Origin/$ORIGIN_ID#sourcespec\"\n# Template for the FocalMechanism object id (smi) which is used to store\n# the scalar moment value.\n# Use $SMI_BASE to indicate smi_base defined above\n# Use $ORIGIN_ID to indicate the id of the associated Origin.\nsmi_focal_mechanism_template = \"$SMI_BASE/FocalMechanism/Origin/$ORIGIN_ID#sourcespec\"\n# -----------------QUAKEML PARAMETERS\n</code></pre>"},{"location":"source/#source-parameters-from-cli","title":"Source Parameters from CLI","text":""},{"location":"source/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake source parameters estimation [-h] -i INVENTORY_FILE_PATH -p PROJECT_FILE_PATH -c CONFIG_FILE_PATH -l LOC_FILES_PATH [-t] -o OUTPUT_DIR_PATH\n</code></pre>"},{"location":"source/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake source -h\n</code></pre> <pre><code>&gt;&gt; surfquake source -i /surfquake_test/metadata/inv_all.xml -p /surfquake_test/project/surfquake_project.pkl -c /surfquake_test/config_files/source_spec.conf -l /surfquake_test/test_nll_final/loc -o /surfquake_test/test_source_final\n</code></pre>"},{"location":"source/#source-parameters-from-library","title":"Source Parameters from Library","text":""},{"location":"source/#classes","title":"Classes","text":"<p><code>Automag</code></p> <pre><code>class Automag:\n\n    def __init__(self, project: SurfProject, locations_directory: str, inventory_path, source_config: str,\n                 output_directory: str, scale: str, gui_mod=None):\n\n        \"\"\"\n        Manage SourceSpec program to estimate source parameters.\n        :param project: SurfProject object.\n        :param inventory_path: Path to metadata file.\n        :param source_config: Path to source config file.\n        :param output_directory: Path to output folder.\n        :param scale: if regional waveforms will cut with small adapted time windows, else will be cut with a \n        long time window\n        \"\"\"\n</code></pre> <p><code>ReadSource</code> <pre><code>class ReadSource:\n    def __init__(self, root_path_to_output: str):\n        \"\"\"\n        The class methods are designed to scan the output of sourcespec\n        root_path_to_output: Root path where sourcespec output is expected\n        \"\"\"\n        self.root_path_to_output = root_path_to_output\n        self.obsfiles = []\n</code></pre></p>"},{"location":"source/#methods","title":"Methods","text":"<p><code>estimate_source_parameters</code> <pre><code># Automag instance method\ndef estimate_source_parameters(self):\n    # Loop over loc folder files and run source parameters estimation\n</code></pre></p> <p><code>generate_source_summary</code> <pre><code># ReadSource instance method\ndef generate_source_summary(self):\n\n    \"\"\"\n    # Generate source parameters summary as dataframe\n    :return List: List of dictionaries containing source parameters\n    \"\"\"\n</code></pre></p> <p><code>write_summary</code> <pre><code># ReadSource instance method\ndef write_summary(self, summary: list, summary_path: str):\n    \"\"\"\n    Transform the summary into txt file using Pandas Dataframe\n    :param summary: List of dictionaries containing source parameters\n    :param summary_path: path to file output including the name of the file.\n    \"\"\"\n</code></pre></p>"},{"location":"source/#example-using-library","title":"Example using library","text":"<pre><code>from surfquakecore.magnitudes.run_magnitudes import Automag\nfrom surfquakecore.magnitudes.source_tools import ReadSource\nfrom surfquakecore.project.surf_project import SurfProject\nimport os\n\nif __name__ == \"__main__\":\n\n    cwd = os.path.dirname(__file__)\n    ## Project definition ##\n    path_to_project = \"/test_surfquake_core/project\"\n    project_path_file = os.path.join(path_to_project, \"surfquake_project.pkl\")\n    print(\"project:\", project_path_file)\n\n    # load the project\n    sp_loaded = SurfProject.load_project(path_to_project_file=project_path_file)\n    print(sp_loaded)\n\n    # Basic input: working_directory, inventory file path and config_file input\n    working_directory = os.path.join(cwd, \"source_estimations\")\n    inventory_path = os.path.join(working_directory, \"inventories\", \"inv_surfquakecore.xml\")\n    path_to_configfiles = os.path.join(working_directory, \"config/source_spec.conf\")\n    locations_directory = os.path.join(working_directory, \"locations\")\n    output_directory = os.path.join(working_directory, \"output\")\n    summary_path = '/Users/roberto/Documents/SurfQuakeCore/examples/source_estimations/source_summary.txt'\n\n    # Running stage\n    mg = Automag(sp_loaded, locations_directory, inventory_path, path_to_configfiles, output_directory, \"regional\")\n    mg.estimate_source_parameters()\n\n    # Now we can read the output and even write a txt summarizing the results\n    rs = ReadSource(output_directory)\n    summary = rs.generate_source_summary()\n    rs.write_summary(summary, summary_path)\n</code></pre>"},{"location":"utils/","title":"Utilities","text":"<p>In this section we show some useful utilities to make easier how to create a metadata file and manage a catalog.</p>"},{"location":"utils/#create-metadata","title":"Create Metadata","text":""},{"location":"utils/#create-metadata-from-cli","title":"Create Metadata from CLI","text":"<p>In many ocasions users only have a stations coordinates files. Other times they have the stations coordinates files and resp files (IMPORTANT: one per stations). In this context, we can use the csv2xml tool to create the metadata that is needed in sufquake for running many modules.</p> <p>First, the stations file must be in this simple way.</p> <pre><code>Net Station Lat Lon elevation start_date starttime end_date endtime\nWM ARNO 37.0988 -6.7322 117.0 2007-01-01  00:00:00 2050-12-31  23:59:59\nWM AVE 33.2981 -7.4133 230.0 2007-01-01  00:00:00 2050-12-31  23:59:59\nWM CART 37.5868 -1.0012 65.0 2007-01-01  00:00:00 2050-12-31  23:59:59\nWM CEU 35.8987 -5.3731 320.0 2007-01-01  00:00:00 2050-12-31  23:59:59\nWM CHAS 35.1837 -2.4304 110.0 2007-01-01  00:00:00 2050-12-31  23:59:59\n</code></pre> <p>Just separated by a simple space. Do not worry to much about starttime and end time. it can be something crazy like in the example. Optionally, the user can incorporate the root path where resp files are saved to be incorporated to the metadata.</p>"},{"location":"utils/#usage","title":"Usage","text":"<pre><code>&gt;&gt; surfquake csv2xml -c [csv_file_path] -r [resp_files_path] -o [output_path] -n [stations_xml_name]\n</code></pre>"},{"location":"utils/#interactive-help","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake csv2xml -h\n</code></pre>"},{"location":"utils/#run-create-metadatafrom-cli","title":"Run Create Metadatafrom CLI","text":"<pre><code>&gt;&gt; surfquake csv2xml -c ./stations_file.txt -r ./resp_files_folder -o ./output_path -n metadata.xml\n</code></pre>"},{"location":"utils/#create-metadata-from-library","title":"Create Metadata from Library","text":""},{"location":"utils/#class","title":"Class","text":"<p><code>Convert</code> <pre><code>class Convert:\n    def __init__(self, file_path, sep='\\s+', resp_files=None):\n        self.file_path = file_path\n        self.respfiles = resp_files\n        self.sep = sep\n        self.all_resps = []\n        if self.respfiles is not None:\n             self.check_resps()\n</code></pre></p>"},{"location":"utils/#method","title":"Method","text":"<p><code>create_stations_xml</code> <pre><code>def create_stations_xml()\n</code></pre></p>"},{"location":"utils/#example-using-library","title":"Example using library","text":"<pre><code>from surfquakecore.utils.create_station_xml import Convert\nstations_file = \"/Users/roberto/Documents/python_notes/my_utils/test_data/coords.txt\"\npath_dest = \"/Users/roberto/Documents/python_notes/my_utils/test_data\"\nresp_files = \"/Users/roberto/Documents/python_notes/my_utils/resp_files\"\nname = \"metadata.xml\"\nsc = Convert(stations_file, resp_files=resp_files)\ndata_map = sc.create_stations_xml()\ninventory = sc.get_data_inventory(data_map)\nsc.write_xml(path_dest, name, inventory)\n</code></pre>"},{"location":"utils/#manage-catalog","title":"Manage catalog","text":"<p>With this tool, the user can create an Obspy catalog merging the information from the location, source spectrum and moment tensor inversion output. Finally, the user can filer the catalog by time spam or geographically. We have added a method to write in human language the catalog. See an example:</p> <pre><code>Event 46: Date 01/02/2022 02:03:00.598999 rms 0.47 s Lat 42.5250 Lon 1.4252 Depth -2.0 km +- 1.3 min_dist 0.089 max_dist 0.621 smin 0.6 km smax 0.7 km ell_azimuth 161.3 gap 65.3 conf_lev 90.0 %\nMagnitudes: Mw 3.58 +- 0.11\nMoment Tensor Solution:\nMw 3.77 Mo 5.07e+14 Nm DC 44.64 % CLVD 22.70 % iso 32.65 % variance_red 34.54\nNodal Plane: Strike 319.9 Dip 40.0 Rake -74.7\nMoment Tensor: mrr -1.05e+14 mtt 2.64e+14 mpp 3.38e+14 mrp 1.09e+13 mrt -7.33e+13 mrp -7.33e+13\nstation phase polarity date time time_residual distance_degrees distance_km azimuth takeoff_angle\nPAND P ? 01/02/2022 02:03:01.900000 -0.32 0.1 9.9 90.8 89.4\nPAND S ? 01/02/2022 02:03:03.330000 0.00 0.1 9.9 90.8 89.4\nARBS P ? 01/02/2022 02:03:02.340000 -0.48 0.1 13.6 137.9 90.8\nARBS S ? 01/02/2022 02:03:04.290000 -0.04 0.1 13.6 137.9 90.8\nCEST P ? 01/02/2022 02:03:03.200000 -0.08 0.1 16.3 300.1 87.5\nCEST S ? 01/02/2022 02:03:05.210000 0.10 0.1 16.3 300.1 87.5\nCSOR P ? 01/02/2022 02:03:05.170000 -0.19 0.3 29.1 234.8 87.9\nCSOR S ? 01/02/2022 02:03:09.050000 0.44 0.3 29.1 234.8 87.9\nSALF S ? 01/02/2022 02:03:09.580000 -0.39 0.3 32.7 322.8 87.4\nCORG P ? 01/02/2022 02:03:05.770000 -0.40 0.3 34.0 194.3 87.1\nCORG S ? 01/02/2022 02:03:10.930000 0.97 0.3 34.0 194.3 87.1\nGENF P ? 01/02/2022 02:03:06.150000 -0.21 0.3 35.1 19.0 87.6\nGENF S ? 01/02/2022 02:03:10.530000 0.26 0.3 35.1 19.0 87.6\nVALC P ? 01/02/2022 02:03:08.590000 -0.70 0.5 53.0 106.7 89.4\nCARF P ? 01/02/2022 02:03:09.900000 -0.38 0.5 59.1 69.0 88.7\nCARF S ? 01/02/2022 02:03:17.300000 0.43 0.5 59.1 69.0 88.7\nFNEB P ? 01/02/2022 02:03:11.830000 -0.09 0.6 69.1 52.5 88.3\nFNEB S ? 01/02/2022 02:03:20.730000 1.11 0.6 69.1 52.5 88.3\n</code></pre>"},{"location":"utils/#manage-catalog-from-cli","title":"Manage Catalog from CLI","text":""},{"location":"utils/#usage_1","title":"Usage","text":"<pre><code>&gt;&gt; surfquake buildcatalog -e [path_event_files_folder] -s [path_source_summary_file] -m [path_mti_summary_file] -t [type_of_catalog] -o [path_to_ouput_folder]\n</code></pre>"},{"location":"utils/#interactive-help_1","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake buildcatalog -h\n</code></pre>"},{"location":"utils/#run-create-metadatafrom-cli_1","title":"Run Create Metadatafrom CLI","text":"<pre><code>&gt;&gt; surfquake buildcatalog -e ./locations -s source_summary.txt -m mti_source_summary.txt -t \"QUAKEXML\" -o ./catalog \n</code></pre>"},{"location":"utils/#manage-catalog-from-library","title":"Manage Catalog from Library","text":""},{"location":"utils/#classes","title":"Classes","text":"<p><code>BuildCatalog</code> <pre><code>class BuildCatalog:\n    def __init__(self, loc_folder, output_path, format=\"QUAKEML\", source_summary_file=None, mti_summary_file=None):\n\n        \"\"\"\n        BuildCatalog class helps to join information from all surfquake outputs and create a catalog\n\n        Attributes:\n        - loc_folder (str): Path to the folder where the user have the locations files *hyp\n        - output_path (str): Output folder path where catalog object and file will be saved\n        - format (str): https://docs.obspy.org/packages/autogen/obspy.core.event.Catalog.write.html\n        - source_summary_file (str): Path to the output file from source module\n        - mti_summary_file (str): Path to the output file from mti module\n\n        Methods:\n        - __init__(root_path): Initialize a new instance of BuildCatalog.\n        - __merge_info(catalog: Catalog): Merges the information from loc, source and mti\n        - build_catalog(): Starts the process to create the catalog from loc files, then calls __merge_info\n        \"\"\"\n</code></pre></p> <p><code>WriteCatalog</code> <pre><code>class WriteCatalog:\n    def __init__(self, path_catalog):\n\n        \"\"\"\n        WriteCatalog class helps to filter the catalog obj write in the most Readable\n\n        Attributes:\n        - path_catalog (str): Path to the pickle file saved when run build_catalog_loc from BuildCatalog class\n\n        Methods:\n        - __init__(root_path): Initialize a new instance of BuildCatalog.\n        - filter_time_catalog(verbose=True, **kwargs): filter the catalog in time span\n        - filter_geographic_catalog(verbose=True, **kwargs): filter the catalog in geographic contrain and magnitude\n        - write_catalog(catalog: Catalog, format, output_path)\n        - write_catalog_surf(catalog: Union[Catalog, None], output_path)\n        \"\"\"\n\n        self.path_catalog = path_catalog\n        self.catalog = []\n        self.__test_catalog()\n</code></pre></p>"},{"location":"utils/#methods","title":"Methods","text":"<p><code>build_catalog_loc</code> Instance method from BuildCatalog Class <pre><code>def build_catalog_loc(self):\n</code></pre></p> <p><code>filter_time_catalog</code> Instance method from WriteCatalog Class <pre><code>    def filter_time_catalog(self, verbose=True, **kwargs):\n\n        \"\"\"\n        Filter the catalog readed in the class instantiation\n        verbose: bool:\n        **kwargs\n        starttime :str: starttime to filter the catalog in format %d/%m/%Y, %H:%M:%S.%f\n        endtime :str: endtime to filter the catalog in format %d/%m/%Y, %H:%M:%S.%f\n        example:\n        wc = WriteCatalog(catalog_path)\n        catalog_filtered = wc.filter_time_catalog(starttime=\"30/01/2022, 00:00:00.0\",\n        endtime=\"20/02/2022, 00:00:00.0\")\n        return :catalog obj:\n        \"\"\"\n</code></pre></p> <p><code>filter_geographic_catalog</code> Instance method from WriteCatalog Class <pre><code>    def filter_geographic_catalog(self, catalog: Union[Catalog, None], verbose= True, **kwargs):\n\n        \"\"\"\n        Filter the catalog readed in the class instantiation or the catalog provided in bu the user when the method\n        is called\n        verbose: bool:\n        catalog obj (optional), if not found it uses catalog from the catalog attribute\n        **kwargs --&gt; All keys must be used to filter success.\n\n        lat_min:float\n        lat_max:float\n        lon_min:float\n        lon_max:float\n        depth_min:float: km\n        depth_max:float: km\n        mag_min:float\n        mag_max:float\n\n        return :catalog obj:\n        \"\"\"\n</code></pre></p> <p><code>write_catalog_surf</code> Instance method from WriteCatalog Class <pre><code>    def write_catalog_surf(self, catalog: Union[Catalog, None], output_path):\n\n        \"\"\"\n        Writes in human language the catalog instantiated with the class\n        verbose: bool:\n        catalog obj (optional), if not found it uses catalog from the catalog attribute\n        \"\"\"\n</code></pre></p>"},{"location":"utils/#examples-using-library","title":"Examples using library","text":"<p>First, We can join all infrmation from located events in your loc folder, with the information of magnitudes and source parameters plus the ourput from Moment Tensor.</p> <pre><code>from surfquakecore.utils.manage_catalog import BuildCatalog\npath_events_folder = \"/Volumes/LaCie/surfquake_test/test_nll_loc\"\npath_source_file = \"/Volumes/LaCie/surfquake_test/catalog_output/sources.txt\"\noutput_path = \"/Volumes/LaCie/surfquake_test/catalog_output\"\nbc = BuildCatalog(loc_folder=path_events_file, source_summary_file=path_source_file, output_path=output_path,\n                      format=\"QUAKEML\")\nbc.build_catalog_loc()\n</code></pre> <p>Secondly, We can play with the catalog, filtering it (filter_time_catalog and filter_geographic_catalog) or writing a human readable version using write_catalog_surf method.</p> <pre><code>from surfquakecore.utils.manage_catalog import WriteCatalog\n\ncatalog_path = \"/Volumes/LaCie/all_andorra/catalog/catalog_obj.pkl\"\noutput_path = \"/Volumes/LaCie/all_andorra/catalog/catalog_surf.txt\"\nwc = WriteCatalog(catalog_path)\nprint(wc.show_help())\nhelp(wc.filter_time_catalog)\nhelp(wc.filter_geographic_catalog)\ncatalog_filtered = wc.filter_time_catalog(starttime=\"30/01/2022, 00:00:00.0\", endtime=\"20/02/2022, 00:00:00.0\")\n\ncatalog_filtered = wc.filter_geographic_catalog(catalog_filtered, lat_min=42.1, lat_max=43.0, lon_min=0.8, lon_max=1.5,\n                                                depth_min=-10, depth_max=20, mag_min=3.4, mag_max=3.9)\n\nwc.write_catalog_surf(catalog=None, output_path=output_path)\n#wc.write_catalog_surf(catalog=catalog_filtered, output_path=output_path)\n\n# Now you can also save the filtered catalog or even plot the catalog using common Obspy Methods\n#catalog_filtered.plot(projection='local')\n</code></pre>"},{"location":"utils/#build-mti-config-files","title":"Build MTI config files","text":"<p>surfQuake core library incorporates and easy way to generate mti Config Files The only thing you need is a previously crated catalog and a mti.ini files that serves of template (just copy and paste the example in the explanation of config file from MTI). The routine will create the mti.ini files using the information from the event catalogs (date, latitude, lngitude, depth and magnitude) and from the rest of the fields from the template. This action will write a mti.ini file per event and ready to be used by MTI toolbox.</p>"},{"location":"utils/#build-mti-config-files-from-cli","title":"Build MTI config files from CLI","text":""},{"location":"utils/#usage_2","title":"Usage","text":"<pre><code>&gt;&gt; surfquake buildmticonfig -c [catalog_file_path] -t [mti_config_template] -o [output_folder] -s [if starttime] -e [if endtime] -l [if lat_min] -a [ if lat_max] -d [if lon_min] -k [if lon_max] -w [if depth_min] -f [depth_max] -g [if mag_min] -p [if mag_max]\n</code></pre>"},{"location":"utils/#interactive-help_2","title":"Interactive help","text":"<pre><code>&gt;&gt; surfquake buildmticonfig -h\n</code></pre>"},{"location":"utils/#run-build-mti-config-files-from-cli","title":"Run Build MTI config files from CLI","text":"<pre><code>&gt;&gt; surfquake buildmticonfig --catalog_file_path /mti_config_test/catalog_obj.pkl --mti_config_template /mti_confis_test/template.ini --output_folder /mti_confis_test --starttime \"30/09/2021, 00:00:00.0\" --endtime \"30/09/2022, 00:00:00.0\" --lat_min 38.0 --lat_max 44.0 --lon_min -2.0 --lon_max 4.0 --depth_min -3.0 --depth_max 50 --mag_min 3.0 --mag_max 4.0\n</code></pre>"},{"location":"utils/#build-mti-config-files-from-library","title":"Build MTI config files from Library","text":""},{"location":"utils/#classes_1","title":"Classes","text":"<p><code>BuildMTIConfigs</code> <pre><code>class BuildMTIConfigs:\n    def __init__(self, catalog_file_path, mti_config: Union[str, MomentTensorInversionConfig], output_path):\n\n        self.catalog_file_path = catalog_file_path\n        self.config_mti_template = mti_config\n        self.output_path = output_path\n        self.catalog = None\n\n        if isinstance(mti_config, str) and os.path.isfile(mti_config):\n            self.mti_template_configuration = (load_mti_configuration(mti_config),)\n\n        else:\n            raise ValueError(f\"mti_config {mti_config} is not valid. It must be a valid .ini file for \"\n                             f\"MomentTensorInversionConfig\")\n</code></pre></p>"},{"location":"utils/#methods_1","title":"Methods","text":"<p><code>write_mti_ini_file</code> <pre><code>    def write_mti_ini_file(self, **kwargs):\n\n        \"\"\"\n        starttime :str: starttime to filter the catalog in format %d/%m/%Y, %H:%M:%S.%f\n        endtime :str: endtime to filter the catalog in format %d/%m/%Y, %H:%M:%S.%f\n        lat_min:float\n        lat_max:float\n        lon_min:float\n        lon_max:float\n        depth_min:float: km\n        depth_max:float: km\n        mag_min:float\n        mag_max:float\n        \"\"\"\n</code></pre></p>"},{"location":"utils/#examples-using-library_1","title":"Examples using library","text":"<pre><code>from surfquakecore.moment_tensor.mti_parse import BuildMTIConfigs\n\ncatalog_path = \"/Users/admin/Desktop/all_andorra/catalog/catalog_obj.pkl\"\noutput_path = \"/Users/admin/Desktop/all_andorra/mti_configs_created\"\nmti_template_path = '/Users/admin/Desktop/all_andorra/mti_configs/mti_template.ini'\n\nbmc = BuildMTIConfigs(catalog_file_path=catalog_path, mti_config=mti_template_path, output_path=output_path)\nbmc.write_mti_ini_file(starttime=\"01/01/2021, 00:00:00.0\", endtime=\"30/10/2022, 00:00:00.0\", lat_min=40.0,\n                       lat_max=44.0, lon_min=0.0, lon_max=4.2, depth_min=-10, depth_max=60,\n                       mag_min=3.0, mag_max=4.0)\n</code></pre>"}]}